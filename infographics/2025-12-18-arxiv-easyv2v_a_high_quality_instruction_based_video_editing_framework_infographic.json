{
  "key_insight": "EasyV2V shows that high-quality, instruction-based video editing can be achieved by cheaply synthesizing diverse video edit pairs from existing expert models and by lifting image edit supervision into videos using shared affine motion and single-frame signals.",
  "problem_solved": "Addresses the difficulty of producing temporally consistent, controllable, and generalizable video edits given limited video-paired training data.",
  "method": [
    "Data synthesis: compose off-the-shelf expert models with fast inverses to generate diverse video edit pairs for training.",
    "Image-to-video lift: convert image edit pairs into pseudo video pairs via single-frame supervision and shared affine motion to impose temporal coherence.",
    "Simple instruction-driven architecture: train a lightweight editing model conditioned on user instructions to achieve controllable, consistent edits across frames."
  ],
  "impact": "Enables practitioners to build robust, instruction-conditioned video editing systems with far less curated video data and simpler pipelines, accelerating development of practical video editing tools.",
  "visual_elements": [
    "Pipeline diagram showing (a) expert composition → synthesized video pairs → training loop → instruction-conditioned editor",
    "Before/after frame sequence (short video strip) illustrating temporal consistency of edits",
    "Illustration of image-to-video lift: single-frame supervision + shared affine motion creating pseudo video pairs",
    "Bar/line chart comparing consistency and fidelity metrics versus baseline video-editing methods"
  ],
  "hashtags": [
    "#VideoEditing",
    "#InstructionTuning",
    "#GenerativeAI",
    "#DiffusionModels",
    "#Multimodal"
  ],
  "paper_id": "2025-12-18-arxiv-easyv2v_a_high_quality_instruction_based_video_editing_framework",
  "paper_title": "EasyV2V: A High-quality Instruction-based Video Editing Framework",
  "paper_category": "Model",
  "paper_date": "2025-12-18",
  "paper_authors": "Jinjie Mai, Chaoyang Wang, Guocheng Gordon Qian, Willi Menapace, Sergey Tulyakov",
  "paper_links": [
    {
      "title": "PDF",
      "url": "https://arxiv.org/pdf/2512.16920v1"
    }
  ],
  "generated_at": "2025-12-19T06:21:39.963189"
}