{
  "key_insight": "Resampling Forcing is a teacher-free, end-to-end training framework that uses a self-resampling scheme to close the train–test gap in autoregressive video diffusion models, removing the need for a separate teacher or discriminator while enabling scalable training from scratch.",
  "problem_solved": "Addresses exposure bias in autoregressive video diffusion — the mismatch between training (ground-truth conditioning) and inference (model-generated conditioning) that degrades long-horizon video generation quality and stability.",
  "method": [
    "Introduce Resampling Forcing: a training protocol that simulates test-time autoregressive conditioning during training without an external teacher.",
    "Self-resampling scheme: periodically replace ground-truth conditioning frames with the model's own predicted frames (resampled) so the model learns to recover from its own errors.",
    "End-to-end, teacher-free training: integrates resampling into standard diffusion optimization, enabling scalable training from scratch without bidirectional teachers or online discriminators."
  ],
  "impact": "Provides a practical, scalable way to train autoregressive video diffusion models that are more robust at generation time, reducing the need for complex teacher models or adversarial components — useful for researchers and engineers building long-horizon video simulators and generative systems.",
  "visual_elements": [
    "Side-by-side schematic: training with ground-truth conditioning vs. training with self-resampling showing reduced train–test mismatch.",
    "Flowchart of the Resampling Forcing loop: predict -> resample -> condition -> train (one-line depiction of end-to-end pipeline).",
    "Before/after sample grid or metrics chart: visual quality and stability improvements over baseline autoregressive training.",
    "Icon set: teacher-free badge, clock/scale for 'scalable', and feedback loop for 'self-resampling'."
  ],
  "hashtags": [
    "#VideoDiffusion",
    "#AutoregressiveAI",
    "#ExposureBias",
    "#GenerativeModels",
    "#SelfResampling"
  ],
  "paper_id": "2025-12-17-arxiv-end_to_end_training_for_autoregressive_video_diffusion_via_self_resampling",
  "paper_title": "End-to-End Training for Autoregressive Video Diffusion via Self-Resampling",
  "paper_category": "Model",
  "paper_date": "2025-12-17",
  "paper_authors": "Yuwei Guo, Ceyuan Yang, Hao He, Yang Zhao, Meng Wei",
  "paper_links": [
    {
      "title": "PDF",
      "url": "https://arxiv.org/pdf/2512.15702v1"
    }
  ],
  "generated_at": "2025-12-18T23:56:18.500149"
}