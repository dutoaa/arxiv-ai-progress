{
  "key_insight": "A practical recipe to convert existing autoregressive (AR) language models into diffusion-based vision-language models (dVLMs), enabling diffusion-style decoding while leveraging the capabilities of strong AR backbones.",
  "problem_solved": "Diffusion vision-language models lag behind mainstream AR-based VLMs because base diffusion language models lack comparable capabilities; this work addresses how to build competitive dVLMs by reusing powerful pretrained AR models instead of training new diffusion LMs from scratch.",
  "method": [
    "Introduce a translation/interface that maps pretrained AR model behavior into a diffusion-compatible component, allowing the AR backbone to be used inside a diffusion generation loop.",
    "Train lightweight adapters or distill from AR outputs into a diffusion score model so the system preserves AR knowledge while supporting diffusion denoising and conditional image-to-text/text-to-image workflows.",
    "Combine diffusion decoding advantages (e.g., flexible parallel generation, robustness) with AR model strengths via joint conditioning and inference strategies tailored for multimodal tasks."
  ],
  "impact": "Enables practitioners to rapidly build high-performing diffusion VLMs by repurposing existing AR models, unlocking diffusion decoding benefits (robustness, parallelism, flexible conditioning) without sacrificing language and multimodal capabilities.",
  "visual_elements": [
    "Architecture diagram: AR model + translator/adapters feeding into a diffusion denoising loop (show data flow and conditioning).",
    "Before vs After bar chart: performance gap between native diffusion VLMs and translated ARâ†’diffusion VLMs.",
    "Decoding pipeline illustration: comparison of autoregressive sequential decoding vs diffusion denoising (parallel steps).",
    "Icon set: AR model, diffusion process (noisy-to-clean), adapter module, multimodal input (image + text)."
  ],
  "hashtags": [
    "#DiffusionModels",
    "#VisionLanguage",
    "#ModelTranslation",
    "#MultimodalAI",
    "#AIResearch"
  ],
  "paper_id": "2025-12-17-arxiv-diffusionvl_translating_any_autoregressive_models_into_diffusion_vision_language",
  "paper_title": "DiffusionVL: Translating Any Autoregressive Models into Diffusion Vision Language Models",
  "paper_category": "Model",
  "paper_date": "2025-12-17",
  "paper_authors": "Lunbin Zeng, Jingfeng Yao, Bencheng Liao, Hongyuan Tao, Wenyu Liu",
  "paper_links": [
    {
      "title": "PDF",
      "url": "https://arxiv.org/pdf/2512.15713v1"
    }
  ],
  "generated_at": "2025-12-18T23:57:23.344214"
}