{
  "key_insight": "Streamo is a real-time streaming video LLM that generalizes beyond QA/captioning to perform many time-sensitive, streaming video tasks by instruction-tuning on a large, task-diverse dataset.",
  "problem_solved": "Existing online video models are narrow (QA or captioning) and struggle with continuous, time-aware tasks; Streamo addresses the need for a single interactive assistant that understands, narrates, grounds events, and answers time-sensitive questions in real time.",
  "method": [
    "Design a streaming-capable multimodal LLM architecture to ingest continuous video and produce low-latency, temporally grounded outputs.",
    "Instruction-tune the model on a large, diverse dataset (Streamo-Instruct-465K) covering narration, action understanding, event captioning, temporal grounding, and time-sensitive QA.",
    "Optimize for real-time inference and multi-task generalization so one model can handle many streaming video tasks interactively."
  ],
  "impact": "Enables practical interactive video assistants for live applications (e.g., monitoring, video coaching, accessibility) and advances multimodal instruction tuning by showing large-scale, task-diverse streaming training improves temporal understanding and responsiveness.",
  "visual_elements": [
    "Pipeline diagram: live video input → streaming encoder → LLM → simultaneous outputs (narration, captions, QA, temporal grounding)",
    "Task coverage chart: icons for narration, action understanding, event captioning, temporal grounding, time-sensitive QA showing one-model support",
    "Dataset highlight: card showing 'Streamo-Instruct-465K' with examples and task distribution",
    "Latency/timeline graphic: annotated timeline showing real-time event detection and grounded answer timestamps"
  ],
  "hashtags": [
    "#VideoLLM",
    "#StreamingAI",
    "#InstructionTuning",
    "#MultimodalAI",
    "#RealTimeVideo"
  ],
  "paper_id": "2025-12-24-arxiv-streaming_video_instruction_tuning",
  "paper_title": "Streaming Video Instruction Tuning",
  "paper_category": "Model",
  "paper_date": "2025-12-24",
  "paper_authors": "Jiaer Xia, Peixian Chen, Mengdan Zhang, Xing Sun, Kaiyang Zhou",
  "paper_links": [
    {
      "title": "PDF",
      "url": "https://arxiv.org/pdf/2512.21334v1"
    }
  ],
  "generated_at": "2025-12-29T06:26:34.768388"
}