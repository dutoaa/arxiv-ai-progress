{
  "key_insight": "You can convert any well-trained Vision Transformer into a self-explainable model without additional training by using class-relevant keypoints and simple counting-based classifiers that produce human-readable evidence for predictions.",
  "problem_solved": "Removes the need for complicated retraining or special architectures to obtain self-explainability for large ViT-based foundation models, enabling transparent, reliable explanations from off-the-shelf models.",
  "method": [
    "Extract interpretable patch/keypoint tokens from a pretrained ViT (using token activations, attention maps or prototype matching) without modifying model weights.",
    "Identify and score class-relevant keypoints and aggregate their presence as simple counts or summed evidence per class.",
    "Use the resulting keypoint-count classifier to make predictions and produce concise, localized explanations (counts, token examples, and heatmaps) instead of opaque logits."
  ],
  "impact": "Provides a lightweight, practical path to trustworthy explanations for practitioners using large ViT models—no retraining, lower cost, easier debugging and auditability for deployed systems.",
  "visual_elements": [
    "Pipeline diagram: pretrained ViT → keypoint extraction → counting classifier → prediction + explanation",
    "Example image: original image with overlaid keypoint markers and class-specific counts (explaining the prediction)",
    "Bar/stack chart: per-class keypoint counts/evidence that led to the chosen label",
    "Icon set: 'no retrain' badge, explainability shield, and lightweight compute symbol to emphasize practicality"
  ],
  "hashtags": [
    "#ExplainableAI",
    "#VisionTransformers",
    "#SelfExplainableModels",
    "#ModelInterpretability",
    "#FoundationModels"
  ],
  "paper_id": "2025-12-19-arxiv-keypoint_counting_classifiers_turning_vision_transformers_into_self_explainable",
  "paper_title": "Keypoint Counting Classifiers: Turning Vision Transformers into Self-Explainable Models Without Training",
  "paper_category": "Model",
  "paper_date": "2025-12-19",
  "paper_authors": "Kristoffer Wickstrøm, Teresa Dorszewski, Siyan Chen, Michael Kampffmeyer, Elisabeth Wetzer",
  "paper_links": [
    {
      "title": "PDF",
      "url": "https://arxiv.org/pdf/2512.17891v1"
    }
  ],
  "generated_at": "2025-12-22T06:22:47.373307"
}