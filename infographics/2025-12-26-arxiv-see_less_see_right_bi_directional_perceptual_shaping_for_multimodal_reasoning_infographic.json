{
  "key_insight": "BiPS (Bi-directional Perceptual Shaping) converts question-conditioned masked visual views into two-way \"where-to-look\" signals that both propose relevant regions and suppress distracting details, enabling VLMs to focus on fine-grained visual evidence (e.g., chart polylines) with lower cost and better cross-domain generalization.",
  "problem_solved": "Current VLM reasoning either injects coarse external visual cues or generates latent tokens that miss fine-grained evidence, generalize poorly across domains, and raise inference-time cost; BiPS addresses focused, efficient attention to subtle visual features.",
  "method": [
    "Generate question-conditioned masked views of the input image to expose candidate visual cues while hiding irrelevant content.",
    "Produce bidirectional signals: positive cues indicating where to attend and negative cues indicating where to ignore, shaping the model's perceptual attention during reasoning.",
    "Integrate these signals into the multimodal reasoning pipeline to improve detection of fine-grained evidence, reduce redundant latent tokens, and lower inference cost."
  ],
  "impact": "Enables more accurate, efficient multimodal reasoning on tasks requiring fine-grained visual evidence (charts, diagrams, small objects) and improves robustness across domains while reducing inference overhead—valuable for deploying VLMs in resource-constrained or production settings.",
  "visual_elements": [
    "Pipeline diagram: input image → question-conditioned masked views → bidirectional signals → VLM reasoning (highlight flow and modules).",
    "Side-by-side attention maps: baseline vs. BiPS showing focused attention on polylines or small chart elements.",
    "Before/after examples: query + image with predicted answer and marked fine-grained evidence locations.",
    "Bar chart comparing inference time, token count, and accuracy across baseline, external-cue, and BiPS approaches."
  ],
  "hashtags": [
    "#VisionLanguage",
    "#MultimodalAI",
    "#EfficientInference",
    "#ExplainableAI",
    "#ChartUnderstanding"
  ],
  "paper_id": "2025-12-26-arxiv-see_less_see_right_bi_directional_perceptual_shaping_for_multimodal_reasoning",
  "paper_title": "See Less, See Right: Bi-directional Perceptual Shaping For Multimodal Reasoning",
  "paper_category": "Model",
  "paper_date": "2025-12-26",
  "paper_authors": "Shuoshuo Zhang, Yizhen Zhang, Jingjing Fu, Lei Song, Jiang Bian",
  "paper_links": [
    {
      "title": "PDF",
      "url": "https://arxiv.org/pdf/2512.22120v1"
    }
  ],
  "generated_at": "2025-12-31T06:23:48.167596"
}