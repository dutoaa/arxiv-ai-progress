{
  "key_insight": "A master LLM coordinates specialized agents to localize question-relevant moments in hour-long videos and extract targeted textual observations, enabling fine-grained, temporally grounded reasoning without relying on lossy global summaries.",
  "problem_solved": "Current long-video QA systems compress long episodes into coarse summaries or use limited tools, which weakens temporal grounding and misses fine-grained visual/textual cues needed to answer detailed questions over hour-long videos.",
  "method": [
    "Master agent (LLM) orchestrates multi-agent reasoning: issues queries, aggregates evidence, and composes final answers.",
    "Grounding agent locates question-relevant temporal segments on the video timeline (timestamped retrieval) instead of relying on a single compressed summary.",
    "Vision agent extracts targeted textual observations (scene descriptions, OCR, object/state changes) from localized segments for precise, evidence-backed answers; iterative query–localize–extract loops refine results."
  ],
  "impact": "Enables more accurate, temporally grounded QA and reasoning over very long videos by preserving fine-grained cues and supporting modular, extensible tool use—beneficial for video analytics, surveillance, education, and multimedia research.",
  "visual_elements": [
    "Pipeline diagram showing Master LLM coordinating Grounding Agent (timeline localization) and Vision Agent (frame/text extraction) with feedback loops.",
    "Video timeline with highlighted localized segments and timestamps to illustrate precise temporal grounding.",
    "Before/after comparison: coarse-summary baseline vs. targeted-extraction multi-agent results (accuracy or fidelity illustration).",
    "Example QA card: question → localized clip thumbnails + extracted textual observations → final LLM answer backed by timestamps."
  ],
  "hashtags": [
    "#LongVideoAgent",
    "#MultimodalLLM",
    "#VideoUnderstanding",
    "#TemporalReasoning",
    "#MultiAgentSystems"
  ],
  "paper_id": "2025-12-23-arxiv-longvideoagent_multi_agent_reasoning_with_long_videos",
  "paper_title": "LongVideoAgent: Multi-Agent Reasoning with Long Videos",
  "paper_category": "Project",
  "paper_date": "2025-12-23",
  "paper_authors": "Runtao Liu, Ziyi Liu, Jiaqi Tang, Yue Ma, Renjie Pi",
  "paper_links": [
    {
      "title": "PDF",
      "url": "https://arxiv.org/pdf/2512.20618v1"
    }
  ],
  "generated_at": "2025-12-24T06:23:11.422674"
}