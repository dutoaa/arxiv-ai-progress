{
  "key_insight": "State-of-the-art vision-language models exhibit a strong popularity bias—performing up to 34% better on famous buildings than ordinary ones—revealing reliance on memorization instead of generalizable multi-modal understanding.",
  "problem_solved": "Identifies and quantifies popularity-driven memorization in VLMs and provides a standardized, large-scale benchmark to evaluate model generalization on an ordinal regression task across globally diverse building images.",
  "method": [
    "Assemble YearGuessr: a large open dataset of 55,546 building images with multi-modal attributes from 157 countries, annotated with continuous ordinal labels.",
    "Design a multi-modal ordinal regression benchmark and evaluation protocol that isolates popularity effects through controlled splits and analysis.",
    "Evaluate popular VLMs on the benchmark, quantify performance gaps (up to 34%) between famous and ordinary buildings, and analyze failure modes highlighting memorization."
  ],
  "impact": "This benchmark exposes a concrete generalization gap in VLMs, guiding researchers and practitioners to audit for popularity bias, improve dataset design, and develop methods that prioritize robust, non-memorized multi-modal reasoning.",
  "visual_elements": [
    "Bar chart comparing model accuracy on famous vs ordinary buildings (highlighting the ~34% gap).",
    "World map heatmap showing geographic distribution of images and dataset coverage across 157 countries.",
    "Pipeline diagram of the benchmark: dataset collection → popularity-controlled splits → model evaluation → bias analysis.",
    "Side-by-side image pairs (famous vs ordinary) with model predictions and attention/heatmap overlays to illustrate memorization failures."
  ],
  "hashtags": [
    "#VisionLanguage",
    "#PopularityBias",
    "#OrdinalRegression",
    "#Benchmark",
    "#YearGuessr"
  ],
  "paper_id": "2025-12-24-arxiv-beyond_memorization_a_multi_modal_ordinal_regression_benchmark_to_expose_popular",
  "paper_title": "Beyond Memorization: A Multi-Modal Ordinal Regression Benchmark to Expose Popularity Bias in Vision-Language Models",
  "paper_category": "Evaluation",
  "paper_date": "2025-12-24",
  "paper_authors": "Li-Zhong Szu-Tu, Ting-Lin Wu, Chia-Jui Chang, He Syu, Yu-Lun Liu",
  "paper_links": [
    {
      "title": "PDF",
      "url": "https://arxiv.org/pdf/2512.21337v1"
    }
  ],
  "generated_at": "2025-12-27T06:23:02.160567"
}