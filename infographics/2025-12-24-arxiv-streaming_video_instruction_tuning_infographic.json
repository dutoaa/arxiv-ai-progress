{
  "key_insight": "Streamo is a real-time streaming video LLM that generalizes across a wide range of time-sensitive video tasks by instruction-tuning on a large streaming video dataset, enabling interactive, low-latency understanding and narration of live video.",
  "problem_solved": "Existing online video models are narrow (QA or captioning) and struggle with continuous, time-sensitive, multi-task video understanding; Streamo addresses the need for a single streaming-capable model that handles narration, action understanding, event captioning, temporal grounding, and time-sensitive QA.",
  "method": [
    "Construct Streamo-Instruct-465K: a large-scale instruction-following streaming video dataset covering diverse temporal tasks and prompts.",
    "Train/instruction-tune a streaming-capable video-to-LLM pipeline that processes incoming frames incrementally to produce low-latency, token-level outputs.",
    "Unify multiple temporal tasks via task-agnostic instruction tuning so the same model can perform narration, grounding, captioning, and QA in real time."
  ],
  "impact": "Streamo simplifies deployment by replacing many task-specific video models with one interactive streaming assistant, enabling real-time applications (robotics, accessibility, AR/VR, live analytics) that require low-latency, multi-task video understanding.",
  "visual_elements": [
    "Architecture diagram: streaming video encoder feeding a language model with incremental tokens and outputs (labels: frames → encoder → LLM → responses).",
    "Timeline / latency visualization: streaming frames on x-axis with corresponding real-time outputs to show low-latency narration and grounding.",
    "Comparison chart: task coverage and latency of Streamo vs prior online video models (captioning-only, QA-only).",
    "Example UI mockups: live narration, temporal event grounding (highlighted timestamps), and time-sensitive QA interactions."
  ],
  "hashtags": [
    "#StreamingAI",
    "#VideoLLM",
    "#InstructionTuning",
    "#RealTimeAI",
    "#Multimodal"
  ],
  "paper_id": "2025-12-24-arxiv-streaming_video_instruction_tuning",
  "paper_title": "Streaming Video Instruction Tuning",
  "paper_category": "Model",
  "paper_date": "2025-12-24",
  "paper_authors": "Jiaer Xia, Peixian Chen, Mengdan Zhang, Xing Sun, Kaiyang Zhou",
  "paper_links": [
    {
      "title": "PDF",
      "url": "https://arxiv.org/pdf/2512.21334v1"
    }
  ],
  "generated_at": "2025-12-26T06:23:09.859690"
}