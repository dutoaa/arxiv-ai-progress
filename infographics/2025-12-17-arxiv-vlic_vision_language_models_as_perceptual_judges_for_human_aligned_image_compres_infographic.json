{
  "key_insight": "State-of-the-art vision-language models can act as reliable perceptual judges: their outputs replicate human binary preferences between compressed images and can be used to evaluate or steer image compression toward human-aligned quality.",
  "problem_solved": "Traditional distortion metrics (e.g., MSE) fail to match human judgments of image quality and collecting large-scale human psycho-visual data is expensive — this work provides a scalable automated judge aligned with people.",
  "method": [
    "Use a pre-trained vision-language model to score pairwise image comparisons (or single-image quality cues) and extract a binary preference signal correlated with human choices.",
    "Calibrate or map VLM outputs to a perceptual score and validate alignment against human judgment datasets and existing perceptual metrics.",
    "Plug the calibrated VLM judge into compression workflows as an evaluation metric or differentiable/approximate loss to train compression models toward human-aligned reconstructions."
  ],
  "impact": "Provides a low-cost, scalable substitute for large human studies that improves image-compression evaluation and training — enabling practitioners to build models that better match human perception with less annotation effort.",
  "visual_elements": [
    "Diagram: pipeline showing compressed image pairs → VLM judge → binary preference → used for training/evaluation of compressor",
    "Bar chart: correlation of VLM-based scores vs. human judgments compared to MSE and prior perceptual metrics",
    "Before/after example grid: same image compressed with MSE-optimized vs. VLM-aligned compressors with human-preferred labels",
    "Icon set: (human head) human judgments, (network) VLM, (gear) compression model, (checkmark) alignment"
  ],
  "hashtags": [
    "#VisionLanguage",
    "#ImageCompression",
    "#PerceptualLoss",
    "#HumanAlignedAI",
    "#VLM"
  ],
  "paper_id": "2025-12-17-arxiv-vlic_vision_language_models_as_perceptual_judges_for_human_aligned_image_compres",
  "paper_title": "VLIC: Vision-Language Models As Perceptual Judges for Human-Aligned Image Compression",
  "paper_category": "Model",
  "paper_date": "2025-12-17",
  "paper_authors": "Kyle Sargent, Ruiqi Gao, Philipp Henzler, Charles Herrmann, Aleksander Holynski",
  "paper_links": [
    {
      "title": "PDF",
      "url": "https://arxiv.org/pdf/2512.15701v1"
    }
  ],
  "generated_at": "2025-12-19T06:23:50.833934"
}