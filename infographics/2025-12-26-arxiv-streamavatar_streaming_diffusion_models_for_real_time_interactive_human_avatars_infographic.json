{
  "key_insight": "A two-stage, streaming-friendly diffusion architecture converts traditionally non-causal diffusion models into a low-latency pipeline, enabling real-time, interactive full-body avatars with diffusion-quality visuals.",
  "problem_solved": "Diffusion-based avatar methods are too slow and non-causal for streaming interactive use and usually focus only on head-and-shoulder; this work makes high-quality, temporally consistent full-body avatar generation feasible for real-time interaction.",
  "method": [
    "Coarse-to-fine two-stage pipeline: a lightweight autoregressive/coarse module predicts temporally consistent low-resolution motion, followed by a diffusion-based refiner that upsamples and adds high-fidelity appearance.",
    "Causal temporal conditioning and efficient sampling strategies tailored for streaming to minimize latency and enable frame-by-frame generation without future context.",
    "Full-body pose/gesture conditioning and spatial compute partitioning (e.g., region-aware refinement) to extend beyond head-and-shoulder while keeping compute tractable."
  ],
  "impact": "Enables practical real-time, interactive digital humans for telepresence, gaming, and virtual assistants by bringing diffusion-quality generation into low-latency streaming settings and supporting full-body gestures.",
  "visual_elements": [
    "Pipeline diagram showing two stages (coarse autoregressive motion -> diffusion-based refinement) with arrows indicating streaming (causal) time flow",
    "Latency vs. quality chart comparing standard diffusion, optimized sampling, and StreamAvatar in frames-per-second and perceptual quality",
    "Before/after full-body avatar frames illustrating coarse prediction vs. refined diffusion output, including gesture examples",
    "Schematic of temporal conditioning (history buffer) and region-aware compute to show how efficiency is achieved"
  ],
  "hashtags": [
    "#DiffusionModels",
    "#RealTimeAvatar",
    "#StreamingAI",
    "#DigitalHumans",
    "#GenerativeAI"
  ],
  "paper_id": "2025-12-26-arxiv-streamavatar_streaming_diffusion_models_for_real_time_interactive_human_avatars",
  "paper_title": "StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars",
  "paper_category": "Model",
  "paper_date": "2025-12-26",
  "paper_authors": "Zhiyao Sun, Ziqiao Peng, Yifeng Ma, Yi Chen, Zhengguang Zhou",
  "paper_links": [
    {
      "title": "PDF",
      "url": "https://arxiv.org/pdf/2512.22065v1"
    }
  ],
  "generated_at": "2025-12-30T06:23:14.910453"
}