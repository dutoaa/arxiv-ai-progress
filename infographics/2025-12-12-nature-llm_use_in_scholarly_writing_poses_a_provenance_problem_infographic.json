{
  "key_insight": "LLM use in scholarly writing creates a provenance problem: it becomes hard to trace which text, claims, or citations originated from humans, which from models, and which from underlying sources—undermining attribution, reproducibility, and accountability.",
  "problem_solved": "Identifies and clarifies the challenge of missing provenance when large language models contribute to academic texts—covering undocumented generation, hallucinated or untraceable citations, ambiguous authorship, and gaps in publisher/reviewer ability to audit and verify contributions.",
  "method": [
    "Systematic analysis of how LLMs are currently used in scholarly writing and where provenance gaps arise (policy review + illustrative examples).",
    "Taxonomy of provenance failure modes (e.g., undocumented generation, source obfuscation, citation hallucination) and their consequences for research integrity.",
    "Proposed directions and requirements for provenance-preserving practices: metadata standards, logging/audit trails, model-output attribution, and policy recommendations for authors and publishers."
  ],
  "impact": "Highlights concrete risks to reproducibility and trust in scientific communication and urges AI tool-builders, publishers, and researchers to adopt provenance metadata, auditing, and disclosure mechanisms to preserve research integrity.",
  "visual_elements": [
    "Flowchart showing content creation path: human draft → LLM edit/generation → source retrieval → final manuscript, with points where provenance is lost.",
    "Before/after example: a short excerpt with an undocumented LLM-generated citation vs. the same excerpt annotated with provenance metadata.",
    "Taxonomy diagram of provenance failure modes (undocumented generation, hallucinated citations, ambiguous authorship, lost data lineage).",
    "Checklist-style icon panel for stakeholders (authors, reviewers, publishers, toolmakers) listing recommended provenance actions."
  ],
  "hashtags": [
    "#ResearchIntegrity",
    "#ScholarlyAI",
    "#Provenance",
    "#LLM",
    "#OpenScience"
  ],
  "paper_id": "2025-12-12-nature-llm_use_in_scholarly_writing_poses_a_provenance_problem",
  "paper_title": "LLM use in scholarly writing poses a provenance problem",
  "paper_category": "Model",
  "paper_date": "2025-12-12",
  "paper_authors": "Brian D. Earp, Haotian Yuan, Julian Koplin, Sebastian Porsdam Mann",
  "paper_links": [
    {
      "title": "View Paper",
      "url": "https://www.nature.com/articles/s42256-025-01159-8"
    },
    {
      "title": "DOI",
      "url": "https://doi.org/10.1038/s42256-025-01159-8"
    }
  ],
  "generated_at": "2025-12-18T22:19:13.017653"
}