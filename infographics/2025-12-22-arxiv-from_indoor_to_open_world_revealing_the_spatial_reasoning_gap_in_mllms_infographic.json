{
  "key_insight": "Multimodal LLMs that excel at semantic tasks still struggle with real-world metric spatial reasoning; a new large-scale outdoor benchmark exposes this gap beyond indoor, qualitative evaluations.",
  "problem_solved": "The lack of open-world/outdoor datasets with verifiable metric ground truth has prevented reliable diagnosis of MLLMs' spatial intelligence—this work fills that evaluation gap.",
  "method": [
    "Construct a large-scale benchmark focused on outdoor/open-world scenes with verifiable metric ground truth for spatial queries.",
    "Design evaluation tasks that require metric spatial reasoning (e.g., distances, orientations, localization) rather than only qualitative or indoor-centric tests.",
    "Systematically evaluate MLLMs on these tasks to quantify the spatial reasoning gap and identify specific failure modes."
  ],
  "impact": "Provides practitioners a rigorous, scalable way to measure and compare spatial capabilities of multimodal models, guiding improvements for robotics, AR, navigation, and grounded AI systems.",
  "visual_elements": [
    "Bar chart: side-by-side comparison of semantic vs. spatial task performance across models to highlight the gap.",
    "Map/image overlay: example outdoor scene with metric ground-truth annotations (distances/orientations) and model answers.",
    "Failure cases: paired panels showing correct human annotation vs. incorrect model spatial reasoning (short captions).",
    "Pipeline diagram: benchmark creation → task generation → model evaluation → gap analysis."
  ],
  "hashtags": [
    "#MLLMs",
    "#SpatialReasoning",
    "#Benchmarking",
    "#MultimodalAI",
    "#Robotics"
  ],
  "paper_id": "2025-12-22-arxiv-from_indoor_to_open_world_revealing_the_spatial_reasoning_gap_in_mllms",
  "paper_title": "From Indoor to Open World: Revealing the Spatial Reasoning Gap in MLLMs",
  "paper_category": "Evaluation",
  "paper_date": "2025-12-22",
  "paper_authors": "Mingrui Wu, Zhaozhi Wang, Fangjinhua Wang, Jiaolong Yang, Marc Pollefeys",
  "paper_links": [
    {
      "title": "PDF",
      "url": "https://arxiv.org/pdf/2512.19683v1"
    }
  ],
  "generated_at": "2025-12-23T06:22:28.202024"
}