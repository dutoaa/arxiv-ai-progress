{
  "key_insight": "A master LLM coordinates specialized agents — a grounding agent that localizes question-relevant segments and a vision agent that extracts targeted textual observations — enabling precise, fine-grained reasoning over hour‑long videos without relying on lossy summaries.",
  "problem_solved": "Enables accurate question answering and temporal grounding over long (hour-scale) videos by avoiding compressive summaries and limited toolsets that miss fine-grained visual and temporal cues.",
  "method": [
    "Master LLM orchestrates a multi-agent loop: issues queries, integrates observations, and performs final reasoning.",
    "Grounding agent performs temporal localization to find short, relevant video segments for each question.",
    "Vision agent extracts targeted textual observations (captions, OCR, object/attribute detections) from localized clips and returns them to the master for iterative reasoning."
  ],
  "impact": "Provides a scalable, modular approach for long-video QA that improves temporal grounding, interpretability, and retrieval of fine-grained evidence — useful for building robust multimodal assistants and video analytics pipelines.",
  "visual_elements": [
    "Architecture diagram showing Master LLM coordinating Grounding Agent and Vision Agent with arrows for query → localization → observation → reasoning",
    "Video timeline with highlighted localized segments and timestamps to illustrate temporal grounding",
    "Side-by-side comparison chart: lossy global summary vs targeted extraction (accuracy, temporal precision, evidence richness)",
    "Example QA flow: question → localized clip → extracted observations (captions/OCR/objects) → final answer"
  ],
  "hashtags": [
    "#LongVideoAgent",
    "#MultimodalLLM",
    "#VideoQA",
    "#TemporalReasoning",
    "#MultiAgentSystems"
  ],
  "paper_id": "2025-12-23-arxiv-longvideoagent_multi_agent_reasoning_with_long_videos",
  "paper_title": "LongVideoAgent: Multi-Agent Reasoning with Long Videos",
  "paper_category": "Project",
  "paper_date": "2025-12-23",
  "paper_authors": "Runtao Liu, Ziyi Liu, Jiaqi Tang, Yue Ma, Renjie Pi",
  "paper_links": [
    {
      "title": "PDF",
      "url": "https://arxiv.org/pdf/2512.20618v1"
    }
  ],
  "generated_at": "2025-12-26T06:24:46.112722"
}