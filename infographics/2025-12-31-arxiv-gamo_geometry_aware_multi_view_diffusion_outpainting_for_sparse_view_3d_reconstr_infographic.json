{
  "key_insight": "A geometry-aware multi-view diffusion outpainting model generates pose-consistent novel views from very few input images, enabling reliable augmentation that substantially improves sparse-view 3D reconstruction.",
  "problem_solved": "Overcomes the poor reconstruction quality when only a small number of camera views are available by synthesizing geometrically consistent additional views to fill coverage gaps.",
  "method": [
    "Geometry-conditioned diffusion outpainting: a diffusion model synthesizes novel image regions and full novel views conditioned on input images, camera poses, and geometric cues (e.g., depth, masks).",
    "Multi-view consistency enforcement: losses and constraints (epipolar/pose awareness, depth/alignment checks) ensure synthesized views are consistent across viewpoints.",
    "Augmentation-to-reconstruction pipeline: generated views are fed into standard multi-view reconstruction backbones (e.g., MVS/NeRF) to produce higher-fidelity 3D geometry from sparse inputs."
  ],
  "impact": "Enables practitioners to produce high-quality 3D reconstructions from far fewer photos, reducing data collection cost and widening applicability of 3D capture (AR/VR, robotics, cultural heritage). It makes diffusion-based view synthesis practical by explicitly encoding geometry for multi-view consistency.",
  "visual_elements": [
    "Pipeline diagram: input sparse views + poses → geometry-aware diffusion outpainting → augmented view set → 3D reconstruction",
    "Before/after comparison: sparse-view reconstruction vs. reconstruction with synthesized views (orthographic or mesh overlays)",
    "Geometry consistency overlay: epipolar lines or depth maps showing alignment between real and synthesized views",
    "Bar/line chart: reconstruction accuracy or completeness vs. number of real views (with and without GaMO augmentation)"
  ],
  "hashtags": [
    "#3DReconstruction",
    "#DiffusionModels",
    "#MultiView",
    "#GeometryAware",
    "#ComputerVision"
  ],
  "paper_id": "2025-12-31-arxiv-gamo_geometry_aware_multi_view_diffusion_outpainting_for_sparse_view_3d_reconstr",
  "paper_title": "GaMO: Geometry-aware Multi-view Diffusion Outpainting for Sparse-View 3D Reconstruction",
  "paper_category": "Model",
  "paper_date": "2025-12-31",
  "paper_authors": "Yi-Chuan Huang, Hao-Jen Chien, Chin-Yang Lin, Ying-Huan Chen, Yu-Lun Liu",
  "paper_links": [
    {
      "title": "PDF",
      "url": "https://arxiv.org/pdf/2512.25073v1"
    }
  ],
  "generated_at": "2026-01-01T06:23:05.237252"
}