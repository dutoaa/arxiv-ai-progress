{
  "key_insight": "Resampling Forcing introduces a teacher-free self-resampling scheme that lets autoregressive video diffusion models be trained end-to-end from scratch, directly addressing exposure bias without relying on bidirectional teachers or discriminators.",
  "problem_solved": "Autoregressive video diffusion models suffer from exposure bias due to train-test mismatch; prior fixes require an external teacher model or online discriminator, complicating training and scaling.",
  "method": [
    "Resampling Forcing framework: during training, the model periodically resamples its own predictions to create realistic autoregressive inputs, simulating test-time conditions.",
    "Self-resampling scheme: replace future ground-truth conditioning with model-sampled frames/latents at training time to expose the model to its own errors and learn corrective behavior.",
    "End-to-end optimization: no bidirectional teacher or discriminator needed, enabling scalable training from scratch using standard loss/optimizer pipelines."
  ],
  "impact": "Makes autoregressive video diffusion models more robust and easier to train at scale by removing dependence on auxiliary teacher/discriminator components, improving long-range coherence and simplifying deployment for generative video tasks.",
  "visual_elements": [
    "Flow diagram of the training loop: ground-truth conditioning vs. self-resampled conditioning to highlight where resampling is applied",
    "Before/after bar chart: exposure-bias metric and sample quality (e.g., FVD) comparing baseline, teacher-based, and Resampling Forcing",
    "Sequence panel: example video frames showing improved long-term consistency with self-resampling",
    "Icon cluster: 'no teacher' badge, scalability/compute icon, autoregressive timeline"
  ],
  "hashtags": [
    "#VideoDiffusion",
    "#AutoregressiveModels",
    "#SelfResampling",
    "#ExposureBias",
    "#EndToEndTraining"
  ],
  "paper_id": "2025-12-17-arxiv-end_to_end_training_for_autoregressive_video_diffusion_via_self_resampling",
  "paper_title": "End-to-End Training for Autoregressive Video Diffusion via Self-Resampling",
  "paper_category": "Model",
  "paper_date": "2025-12-17",
  "paper_authors": "Yuwei Guo, Ceyuan Yang, Hao He, Yang Zhao, Meng Wei",
  "paper_links": [
    {
      "title": "PDF",
      "url": "https://arxiv.org/pdf/2512.15702v1"
    }
  ],
  "generated_at": "2025-12-18T22:52:50.857237"
}