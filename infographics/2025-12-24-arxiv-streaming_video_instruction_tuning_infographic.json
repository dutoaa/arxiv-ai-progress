{
  "key_insight": "Streamo converts large language models into real-time, general-purpose streaming video assistants by instruction-tuning on a large multi-task streaming dataset, enabling diverse time-sensitive video understanding (narration, grounding, QA) with low latency.",
  "problem_solved": "Existing online video models are task-specialized (QA or captioning) and struggle with continuous, time-sensitive interactions; Streamo addresses the need for a single model that can handle a broad spectrum of streaming video tasks in real time.",
  "method": [
    "Assemble Streamo-Instruct-465K: a large-scale, multi-task instruction-following dataset tailored to streaming video scenarios (narration, action/event captioning, temporal grounding, time-sensitive QA).",
    "Instruction-tune a video-enabled LLM to accept continuous (streaming) visual input and produce temporally-aware, incremental outputs across tasks.",
    "Optimize an inference pipeline for low-latency, incremental responses (real-time narration, event detection/grounding, and interactive QA) while maintaining multi-task versatility."
  ],
  "impact": "Provides a unified approach for building interactive, real-time video assistants useful for monitoring, accessibility, robotics, and media tools; reduces the need for many task-specific models and enables richer temporal understanding in deployed systems.",
  "visual_elements": [
    "Architecture diagram: streaming video encoder → temporal context buffer → instruction-tuned LLM → multi-task outputs (narration, grounding, QA).",
    "Timeline visualization: incoming video frames with aligned incremental outputs (live captions, detected events, grounded timestamps).",
    "Multi-task example panel: side-by-side examples showing narration, event captioning, temporal grounding, and time-sensitive QA on the same clip.",
    "Dataset infographic: size (465K), task breakdown, and examples to illustrate the instruction-tuning scale and diversity."
  ],
  "hashtags": [
    "#StreamingVideo",
    "#VideoLLM",
    "#InstructionTuning",
    "#RealTimeAI",
    "#Multimodal"
  ],
  "paper_id": "2025-12-24-arxiv-streaming_video_instruction_tuning",
  "paper_title": "Streaming Video Instruction Tuning",
  "paper_category": "Model",
  "paper_date": "2025-12-24",
  "paper_authors": "Jiaer Xia, Peixian Chen, Mengdan Zhang, Xing Sun, Kaiyang Zhou",
  "paper_links": [
    {
      "title": "PDF",
      "url": "https://arxiv.org/pdf/2512.21334v1"
    }
  ],
  "generated_at": "2025-12-27T06:22:10.457106"
}