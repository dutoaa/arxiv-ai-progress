[
  {
    "id": "2025-12-16-arxiv-memflow_flowing_adaptive_memory_for_consistent_and_efficient_long_video_narrativ",
    "date": "2025-12-16",
    "title": "MemFlow: Flowing Adaptive Memory for Consistent and Efficient Long Video Narratives",
    "authors": "Sihui Ji, Xi Chen, Shuai Yang, Xin Tao, Pengfei Wan",
    "abstract": "The core challenge for streaming video generation is maintaining the content consistency in long context, which poses high requirement for the memory design. Most existing solutions maintain the memory by compressing historical frames with predefined strategies. However, different to-generate video chunks should refer to different historical cues, which is hard to satisfy with fixed strategies. In this work, we propose MemFlow to address this problem. Specifically, before generating the coming c",
    "category": "Model",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "model"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.14699v1"
      }
    ],
    "source_file": "papers/weekly/2025-W50/2025-12-16-arxiv-memflow_flowing_adaptive_memory_for_consistent_and_efficient_long_video_narrativ.yaml"
  },
  {
    "id": "2025-12-16-arxiv-native_and_compact_structured_latents_for_3d_generation",
    "date": "2025-12-16",
    "title": "Native and Compact Structured Latents for 3D Generation",
    "authors": "Jianfeng Xiang, Xiaoxue Chen, Sicheng Xu, Ruicheng Wang, Zelong Lv",
    "abstract": "Recent advancements in 3D generative modeling have significantly improved the generation realism, yet the field is still hampered by existing representations, which struggle to capture assets with complex topologies and detailed appearance. This paper present an approach for learning a structured latent representation from native 3D data to address this challenge. At its core is a new sparse voxel structure called O-Voxel, an omni-voxel representation that encodes both geometry and appearance. O",
    "category": "Hardware/Infra",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "hardware_infra"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.14692v1"
      }
    ],
    "source_file": "papers/weekly/2025-W50/2025-12-16-arxiv-native_and_compact_structured_latents_for_3d_generation.yaml"
  },
  {
    "id": "2025-12-16-arxiv-early_warning_index_for_patient_deteriorations_in_hospitals",
    "date": "2025-12-16",
    "title": "Early Warning Index for Patient Deteriorations in Hospitals",
    "authors": "Dimitris Bertsimas, Yu Ma, Kimberly Villalobos Carballo, Gagan Singh, Michal Laskowski",
    "abstract": "Hospitals lack automated systems to harness the growing volume of heterogeneous clinical and operational data to effectively forecast critical events. Early identification of patients at risk for deterioration is essential not only for patient care quality monitoring but also for physician care management. However, translating varied data streams into accurate and interpretable risk assessments poses significant challenges due to inconsistent data formats. We develop a multimodal machine learnin",
    "category": "Project",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "project"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.14683v1"
      }
    ],
    "source_file": "papers/weekly/2025-W50/2025-12-16-arxiv-early_warning_index_for_patient_deteriorations_in_hospitals.yaml"
  },
  {
    "id": "2025-12-16-arxiv-crisp_contact_guided_real2sim_from_monocular_video_with_planar_scene_primitives",
    "date": "2025-12-16",
    "title": "CRISP: Contact-Guided Real2Sim from Monocular Video with Planar Scene Primitives",
    "authors": "Zihan Wang, Jiashun Wang, Jeff Tan, Yiwen Zhao, Jessica Hodgins",
    "abstract": "We introduce CRISP, a method that recovers simulatable human motion and scene geometry from monocular video. Prior work on joint human-scene reconstruction relies on data-driven priors and joint optimization with no physics in the loop, or recovers noisy geometry with artifacts that cause motion tracking policies with scene interactions to fail. In contrast, our key insight is to recover convex, clean, and simulation-ready geometry by fitting planar primitives to a point cloud reconstruction of ",
    "category": "Model",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "model"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.14696v1"
      }
    ],
    "source_file": "papers/weekly/2025-W50/2025-12-16-arxiv-crisp_contact_guided_real2sim_from_monocular_video_with_planar_scene_primitives.yaml"
  },
  {
    "id": "2025-12-16-arxiv-timelens_rethinking_video_temporal_grounding_with_multimodal_llms",
    "date": "2025-12-16",
    "title": "TimeLens: Rethinking Video Temporal Grounding with Multimodal LLMs",
    "authors": "Jun Zhang, Teng Wang, Yuying Ge, Yixiao Ge, Xinhao Li",
    "abstract": "This paper does not introduce a novel method but instead establishes a straightforward, incremental, yet essential baseline for video temporal grounding (VTG), a core capability in video understanding. While multimodal large language models (MLLMs) excel at various video understanding tasks, the recipes for optimizing them for VTG remain under-explored. In this paper, we present TimeLens, a systematic investigation into building MLLMs with strong VTG ability, along two primary dimensions: data q",
    "category": "Model",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "model"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.14698v1"
      }
    ],
    "source_file": "papers/weekly/2025-W50/2025-12-16-arxiv-timelens_rethinking_video_temporal_grounding_with_multimodal_llms.yaml"
  },
  {
    "id": "2025-12-16-arxiv-universal_reasoning_model",
    "date": "2025-12-16",
    "title": "Universal Reasoning Model",
    "authors": "Zitian Gao, Lynx Chen, Yihao Xiao, He Xing, Ran Tao",
    "abstract": "Universal transformers (UTs) have been widely used for complex reasoning tasks such as ARC-AGI and Sudoku, yet the specific sources of their performance gains remain underexplored. In this work, we systematically analyze UTs variants and show that improvements on ARC-AGI primarily arise from the recurrent inductive bias and strong nonlinear components of Transformer, rather than from elaborate architectural designs. Motivated by this finding, we propose the Universal Reasoning Model (URM), which",
    "category": "Model",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "model"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.14693v1"
      }
    ],
    "source_file": "papers/weekly/2025-W50/2025-12-16-arxiv-universal_reasoning_model.yaml"
  },
  {
    "id": "2025-12-16-arxiv-chip_adaptive_compliance_for_humanoid_control_through_hindsight_perturbation",
    "date": "2025-12-16",
    "title": "CHIP: Adaptive Compliance for Humanoid Control through Hindsight Perturbation",
    "authors": "Sirui Chen, Zi-ang Cao, Zhengyi Luo, Fernando Castañeda, Chenran Li",
    "abstract": "Recent progress in humanoid robots has unlocked agile locomotion skills, including backflipping, running, and crawling. Yet it remains challenging for a humanoid robot to perform forceful manipulation tasks such as moving objects, wiping, and pushing a cart. We propose adaptive Compliance Humanoid control through hIsight Perturbation (CHIP), a plug-and-play module that enables controllable end-effector stiffness while preserving agile tracking of dynamic reference motions. CHIP is easy to implem",
    "category": "Policy",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "policy"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.14689v1"
      }
    ],
    "source_file": "papers/weekly/2025-W50/2025-12-16-arxiv-chip_adaptive_compliance_for_humanoid_control_through_hindsight_perturbation.yaml"
  },
  {
    "id": "2025-12-16-arxiv-spherical_leech_quantization_for_visual_tokenization_and_generation",
    "date": "2025-12-16",
    "title": "Spherical Leech Quantization for Visual Tokenization and Generation",
    "authors": "Yue Zhao, Hanwen Jiang, Zhenlin Xu, Chutong Yang, Ehsan Adeli",
    "abstract": "Non-parametric quantization has received much attention due to its efficiency on parameters and scalability to a large codebook. In this paper, we present a unified formulation of different non-parametric quantization methods through the lens of lattice coding. The geometry of lattice codes explains the necessity of auxiliary loss terms when training auto-encoders with certain existing lookup-free quantization variants such as BSQ. As a step forward, we explore a few possible candidates, includi",
    "category": "Model",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "model"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.14697v1"
      }
    ],
    "source_file": "papers/weekly/2025-W50/2025-12-16-arxiv-spherical_leech_quantization_for_visual_tokenization_and_generation.yaml"
  },
  {
    "id": "2025-12-16-arxiv-mmgr_multi_modal_generative_reasoning",
    "date": "2025-12-16",
    "title": "MMGR: Multi-Modal Generative Reasoning",
    "authors": "Zefan Cai, Haoyi Qiu, Tianyi Ma, Haozhe Zhao, Gengze Zhou",
    "abstract": "Video foundation models generate visually realistic and temporally coherent content, but their reliability as world simulators depends on whether they capture physical, logical, and spatial constraints. Existing metrics such as Frechet Video Distance (FVD) emphasize perceptual quality and overlook reasoning failures, including violations of causality, physics, and global consistency. We introduce MMGR (Multi-Modal Generative Reasoning Evaluation and Benchmark), a principled evaluation framework ",
    "category": "Evaluation",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "evaluation"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.14691v1"
      }
    ],
    "source_file": "papers/weekly/2025-W50/2025-12-16-arxiv-mmgr_multi_modal_generative_reasoning.yaml"
  },
  {
    "id": "2025-12-16-arxiv-spoken_dialogsum_an_emotion_rich_conversational_dataset_for_spoken_dialogue_summ",
    "date": "2025-12-16",
    "title": "Spoken DialogSum: An Emotion-Rich Conversational Dataset for Spoken Dialogue Summarization",
    "authors": "Yen-Ju Lu, Kunxiao Gao, Mingrui Liang, Helin Wang, Thomas Thebaud",
    "abstract": "Recent audio language models can follow long conversations. However, research on emotion-aware or spoken dialogue summarization is constrained by the lack of data that links speech, summaries, and paralinguistic cues. We introduce Spoken DialogSum, the first corpus aligning raw conversational audio with factual summaries, emotion-rich summaries, and utterance-level labels for speaker age, gender, and emotion. The dataset is built in two stages: first, an LLM rewrites DialogSum scripts with Switc",
    "category": "Project",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "project"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.14687v1"
      }
    ],
    "source_file": "papers/weekly/2025-W50/2025-12-16-arxiv-spoken_dialogsum_an_emotion_rich_conversational_dataset_for_spoken_dialogue_summ.yaml"
  },
  {
    "id": "2025-12-15-arxiv-agentiad_tool_augmented_single_agent_for_industrial_anomaly_detection",
    "date": "2025-12-15",
    "title": "AgentIAD: Tool-Augmented Single-Agent for Industrial Anomaly Detection",
    "authors": "Junwen Miao, Penghui Du, Yi Liu, Yu Wang, Yan Wang",
    "abstract": "Industrial anomaly detection (IAD) is difficult due to the scarcity of normal reference samples and the subtle, localized nature of many defects. Single-pass vision-language models (VLMs) often overlook small abnormalities and lack explicit mechanisms to compare against canonical normal patterns. We propose AgentIAD, a tool-driven agentic framework that enables multi-stage visual inspection. The agent is equipped with a Perceptive Zoomer (PZ) for localized fine-grained analysis and a Comparative",
    "category": "Model",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "model"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.13671v1"
      }
    ],
    "source_file": "papers/weekly/2025-W50/2025-12-15-arxiv-agentiad_tool_augmented_single_agent_for_industrial_anomaly_detection.yaml"
  },
  {
    "id": "2025-12-15-arxiv-laser_layer_wise_scale_alignment_for_training_free_streaming_4d_reconstruction",
    "date": "2025-12-15",
    "title": "LASER: Layer-wise Scale Alignment for Training-Free Streaming 4D Reconstruction",
    "authors": "Tianye Ding, Yiming Xie, Yiqing Liang, Moitreya Chatterjee, Pedro Miraldo",
    "abstract": "Recent feed-forward reconstruction models like VGGT and $π^3$ achieve impressive reconstruction quality but cannot process streaming videos due to quadratic memory complexity, limiting their practical deployment. While existing streaming methods address this through learned memory mechanisms or causal attention, they require extensive retraining and may not fully leverage the strong geometric priors of state-of-the-art offline models. We propose LASER, a training-free framework that converts an ",
    "category": "Model",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "model"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.13680v1"
      }
    ],
    "source_file": "papers/weekly/2025-W50/2025-12-15-arxiv-laser_layer_wise_scale_alignment_for_training_free_streaming_4d_reconstruction.yaml"
  },
  {
    "id": "2025-12-15-arxiv-a_scientific_reasoning_model_for_organic_synthesis_procedure_generation",
    "date": "2025-12-15",
    "title": "A Scientific Reasoning Model for Organic Synthesis Procedure Generation",
    "authors": "Guoqing Liu, Junren Li, Zihan Zhao, Eray Inanc, Krzysztof Maziarz",
    "abstract": "Solving computer-aided synthesis planning is essential for enabling fully automated, robot-assisted synthesis workflows and improving the efficiency of drug discovery. A key challenge, however, is bridging the gap between computational route design and practical laboratory execution, particularly the accurate prediction of viable experimental procedures for each synthesis step. In this work, we present QFANG, a scientific reasoning language model capable of generating precise, structured experim",
    "category": "Model",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "model"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.13668v1"
      }
    ],
    "source_file": "papers/weekly/2025-W50/2025-12-15-arxiv-a_scientific_reasoning_model_for_organic_synthesis_procedure_generation.yaml"
  },
  {
    "id": "2025-12-15-arxiv-towards_interactive_intelligence_for_digital_humans",
    "date": "2025-12-15",
    "title": "Towards Interactive Intelligence for Digital Humans",
    "authors": "Yiyi Cai, Xuangeng Chu, Xiwei Gao, Sitong Gong, Yifei Huang",
    "abstract": "We introduce Interactive Intelligence, a novel paradigm of digital human that is capable of personality-aligned expression, adaptive interaction, and self-evolution. To realize this, we present Mio (Multimodal Interactive Omni-Avatar), an end-to-end framework composed of five specialized modules: Thinker, Talker, Face Animator, Body Animator, and Renderer. This unified architecture integrates cognitive reasoning with real-time multimodal embodiment to enable fluid, consistent interaction. Furthe",
    "category": "Model",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "model"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.13674v1"
      }
    ],
    "source_file": "papers/weekly/2025-W50/2025-12-15-arxiv-towards_interactive_intelligence_for_digital_humans.yaml"
  },
  {
    "id": "2025-12-15-arxiv-from_code_to_field_evaluating_the_robustness_of_convolutional_neural_networks_fo",
    "date": "2025-12-15",
    "title": "From Code to Field: Evaluating the Robustness of Convolutional Neural Networks for Disease Diagnosis in Mango Leaves",
    "authors": "Gabriel Vitorino de Andrade, Saulo Roberto dos Santos, Itallo Patrick Castro Alves da Silva, Emanuel Adler Medeiros Pereira, Erick de Andrade Barboza",
    "abstract": "The validation and verification of artificial intelligence (AI) models through robustness assessment are essential to guarantee the reliable performance of intelligent systems facing real-world challenges, such as image corruptions including noise, blurring, and weather variations. Despite the global importance of mango (Mangifera indica L.), there is a lack of studies on the robustness of models for the diagnosis of disease in its leaves. This paper proposes a methodology to evaluate convolutio",
    "category": "Model",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "model"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.13641v1"
      }
    ],
    "source_file": "papers/weekly/2025-W50/2025-12-15-arxiv-from_code_to_field_evaluating_the_robustness_of_convolutional_neural_networks_fo.yaml"
  },
  {
    "id": "2025-12-15-arxiv-litept_lighter_yet_stronger_point_transformer",
    "date": "2025-12-15",
    "title": "LitePT: Lighter Yet Stronger Point Transformer",
    "authors": "Yuanwen Yue, Damien Robert, Jianyuan Wang, Sunghwan Hong, Jan Dirk Wegner",
    "abstract": "Modern neural architectures for 3D point cloud processing contain both convolutional layers and attention blocks, but the best way to assemble them remains unclear. We analyse the role of different computational blocks in 3D point cloud networks and find an intuitive behaviour: convolution is adequate to extract low-level geometry at high-resolution in early layers, where attention is expensive without bringing any benefits; attention captures high-level semantics and context in low-resolution, ",
    "category": "Model",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "model"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.13689v1"
      }
    ],
    "source_file": "papers/weekly/2025-W50/2025-12-15-arxiv-litept_lighter_yet_stronger_point_transformer.yaml"
  },
  {
    "id": "2025-12-15-arxiv-embedding_based_rankings_of_educational_resources_based_on_learning_outcome_alig",
    "date": "2025-12-15",
    "title": "Embedding-Based Rankings of Educational Resources based on Learning Outcome Alignment: Benchmarking, Expert Validation, and Learner Performance",
    "authors": "Mohammadreza Molavi, Mohammad Moein, Mohammadreza Tavakoli, Abdolali Faraji, Stefan T. Mol",
    "abstract": "As the online learning landscape evolves, the need for personalization is increasingly evident. Although educational resources are burgeoning, educators face challenges selecting materials that both align with intended learning outcomes and address diverse learner needs. Large Language Models (LLMs) are attracting growing interest for their potential to create learning resources that better support personalization, but verifying coverage of intended outcomes still requires human alignment review",
    "category": "Evaluation",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "evaluation"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.13658v1"
      }
    ],
    "source_file": "papers/weekly/2025-W50/2025-12-15-arxiv-embedding_based_rankings_of_educational_resources_based_on_learning_outcome_alig.yaml"
  },
  {
    "id": "2025-12-15-arxiv-beyond_surface_form_a_pipeline_for_semantic_analysis_in_alzheimer_s_disease_dete",
    "date": "2025-12-15",
    "title": "Beyond surface form: A pipeline for semantic analysis in Alzheimer's Disease detection from spontaneous speech",
    "authors": "Dylan Phelps, Rodrigo Wilkens, Edward Gow-Smith, Lilian Hubner, Bárbara Malcorra",
    "abstract": "Alzheimer's Disease (AD) is a progressive neurodegenerative condition that adversely affects cognitive abilities. Language-related changes can be automatically identified through the analysis of outputs from linguistic assessment tasks, such as picture description. Language models show promise as a basis for screening tools for AD, but their limited interpretability poses a challenge in distinguishing true linguistic markers of cognitive decline from surface-level textual patterns. To address th",
    "category": "Evaluation",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "evaluation"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.13685v1"
      }
    ],
    "source_file": "papers/weekly/2025-W50/2025-12-15-arxiv-beyond_surface_form_a_pipeline_for_semantic_analysis_in_alzheimer_s_disease_dete.yaml"
  },
  {
    "id": "2025-12-15-arxiv-robotracer_mastering_spatial_trace_with_reasoning_in_vision_language_models_for",
    "date": "2025-12-15",
    "title": "RoboTracer: Mastering Spatial Trace with Reasoning in Vision-Language Models for Robotics",
    "authors": "Enshen Zhou, Cheng Chi, Yibo Li, Jingkun An, Jiayuan Zhang",
    "abstract": "Spatial tracing, as a fundamental embodied interaction ability for robots, is inherently challenging as it requires multi-step metric-grounded reasoning compounded with complex spatial referring and real-world metric measurement. However, existing methods struggle with this compositional task. To this end, we propose RoboTracer, a 3D-aware VLM that first achieves both 3D spatial referring and measuring via a universal spatial encoder and a regression-supervised decoder to enhance scale awareness",
    "category": "Evaluation",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "evaluation"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.13660v1"
      }
    ],
    "source_file": "papers/weekly/2025-W50/2025-12-15-arxiv-robotracer_mastering_spatial_trace_with_reasoning_in_vision_language_models_for.yaml"
  },
  {
    "id": "2025-12-15-arxiv-world_models_can_leverage_human_videos_for_dexterous_manipulation",
    "date": "2025-12-15",
    "title": "World Models Can Leverage Human Videos for Dexterous Manipulation",
    "authors": "Raktim Gautam Goswami, Amir Bar, David Fan, Tsung-Yen Yang, Gaoyue Zhou",
    "abstract": "Dexterous manipulation is challenging because it requires understanding how subtle hand motion influences the environment through contact with objects. We introduce DexWM, a Dexterous Manipulation World Model that predicts the next latent state of the environment conditioned on past states and dexterous actions. To overcome the scarcity of dexterous manipulation datasets, DexWM is trained on over 900 hours of human and non-dexterous robot videos. To enable fine-grained dexterity, we find that pr",
    "category": "Model",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "model"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.13644v1"
      }
    ],
    "source_file": "papers/weekly/2025-W50/2025-12-15-arxiv-world_models_can_leverage_human_videos_for_dexterous_manipulation.yaml"
  },
  {
    "id": "2025-12-15-arxiv-jova_unified_multimodal_learning_for_joint_video_audio_generation",
    "date": "2025-12-15",
    "title": "JoVA: Unified Multimodal Learning for Joint Video-Audio Generation",
    "authors": "Xiaohu Huang, Hao Zhou, Qiangpeng Yang, Shilei Wen, Kai Han",
    "abstract": "In this paper, we present JoVA, a unified framework for joint video-audio generation. Despite recent encouraging advances, existing methods face two critical limitations. First, most existing approaches can only generate ambient sounds and lack the capability to produce human speech synchronized with lip movements. Second, recent attempts at unified human video-audio generation typically rely on explicit fusion or modality-specific alignment modules, which introduce additional architecture desig",
    "category": "Model",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "model"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.13677v1"
      }
    ],
    "source_file": "papers/weekly/2025-W50/2025-12-15-arxiv-jova_unified_multimodal_learning_for_joint_video_audio_generation.yaml"
  },
  {
    "id": "2025-12-15-arxiv-towards_effective_model_editing_for_llm_personalization",
    "date": "2025-12-15",
    "title": "Towards Effective Model Editing for LLM Personalization",
    "authors": "Baixiang Huang, Limeng Cui, Jiapeng Liu, Haoran Wang, Jiawei Xu",
    "abstract": "Personalization is becoming indispensable for LLMs to align with individual user preferences and needs. Yet current approaches are often computationally expensive, data-intensive, susceptible to catastrophic forgetting, and prone to performance degradation in multi-turn interactions or when handling implicit queries. To address these challenges, we conceptualize personalization as a model editing task and introduce Personalization Editing, a framework that applies localized edits guided by clust",
    "category": "Model",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "model"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.13676v1"
      }
    ],
    "source_file": "papers/weekly/2025-W50/2025-12-15-arxiv-towards_effective_model_editing_for_llm_personalization.yaml"
  },
  {
    "id": "2025-12-15-arxiv-recurrent_video_masked_autoencoders",
    "date": "2025-12-15",
    "title": "Recurrent Video Masked Autoencoders",
    "authors": "Daniel Zoran, Nikhil Parthasarathy, Yi Yang, Drew A Hudson, Joao Carreira",
    "abstract": "We present Recurrent Video Masked-Autoencoders (RVM): a novel video representation learning approach that uses a transformer-based recurrent neural network to aggregate dense image features over time, effectively capturing the spatio-temporal structure of natural video data. RVM learns via an asymmetric masked prediction task requiring only a standard pixel reconstruction objective. This design yields a highly efficient ``generalist'' encoder: RVM achieves competitive performance with state-of-t",
    "category": "Model",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "model"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.13684v1"
      }
    ],
    "source_file": "papers/weekly/2025-W50/2025-12-15-arxiv-recurrent_video_masked_autoencoders.yaml"
  },
  {
    "id": "2025-12-12-arxiv-from_signal_to_turn_interactional_friction_in_modular_speech_to_speech_pipelines",
    "date": "2025-12-12",
    "title": "From Signal to Turn: Interactional Friction in Modular Speech-to-Speech Pipelines",
    "authors": "Titaya Mairittha, Tanakon Sawanglok, Panuwit Raden, Jirapast Buntub, Thanapat Warunee",
    "abstract": "While voice-based AI systems have achieved remarkable generative capabilities, their interactions often feel conversationally broken. This paper examines the interactional friction that emerges in modular Speech-to-Speech Retrieval-Augmented Generation (S2S-RAG) pipelines. By analyzing a representative production system, we move beyond simple latency metrics to identify three recurring patterns of conversational breakdown: (1) Temporal Misalignment, where system delays violate user expectations ",
    "category": "Evaluation",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "evaluation"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11724v1"
      }
    ],
    "source_file": "papers/weekly/2025-12-12-arxiv-from_signal_to_turn_interactional_friction_in_modular_speech_to_speech_pipelines.yaml"
  },
  {
    "id": "2025-12-12-arxiv-cognisnn_enabling_neuron_expandability_pathway_reusability_and_dynamic_configura",
    "date": "2025-12-12",
    "title": "CogniSNN: Enabling Neuron-Expandability, Pathway-Reusability, and Dynamic-Configurability with Random Graph Architectures in Spiking Neural Networks",
    "authors": "Yongsheng Huang, Peibo Duan, Yujie Wu, Kai Sun, Zhipeng Liu",
    "abstract": "Spiking neural networks (SNNs), regarded as the third generation of artificial neural networks, are expected to bridge the gap between artificial intelligence and computational neuroscience. However, most mainstream SNN research directly adopts the rigid, chain-like hierarchical architecture of traditional artificial neural networks (ANNs), ignoring key structural characteristics of the brain. Biological neurons are stochastically interconnected, forming complex neural pathways that exhibit Neur",
    "category": "Hardware/Infra",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "hardware_infra"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11743v1"
      }
    ],
    "source_file": "papers/weekly/2025-12-12-arxiv-cognisnn_enabling_neuron_expandability_pathway_reusability_and_dynamic_configura.yaml"
  },
  {
    "id": "2025-12-12-arxiv-super_suffixes_bypassing_text_generation_alignment_and_guard_models_simultaneous",
    "date": "2025-12-12",
    "title": "Super Suffixes: Bypassing Text Generation Alignment and Guard Models Simultaneously",
    "authors": "Andrew Adiletta, Kathryn Adiletta, Kemal Derya, Berk Sunar",
    "abstract": "The rapid deployment of Large Language Models (LLMs) has created an urgent need for enhanced security and privacy measures in Machine Learning (ML). LLMs are increasingly being used to process untrusted text inputs and even generate executable code, often while having access to sensitive system controls. To address these security concerns, several companies have introduced guard models, which are smaller, specialized models designed to protect text generation models from adversarial or malicious",
    "category": "Incident",
    "source": "arxiv",
    "score": 95,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "incident"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11783v1"
      }
    ],
    "source_file": "papers/weekly/2025-12-12-arxiv-super_suffixes_bypassing_text_generation_alignment_and_guard_models_simultaneous.yaml"
  },
  {
    "id": "2025-12-12-arxiv-conditional_coverage_diagnostics_for_conformal_prediction",
    "date": "2025-12-12",
    "title": "Conditional Coverage Diagnostics for Conformal Prediction",
    "authors": "Sacha Braun, David Holzmüller, Michael I. Jordan, Francis Bach",
    "abstract": "Evaluating conditional coverage remains one of the most persistent challenges in assessing the reliability of predictive systems. Although conformal methods can give guarantees on marginal coverage, no method can guarantee to produce sets with correct conditional coverage, leaving practitioners without a clear way to interpret local deviations. To overcome sample-inefficiency and overfitting issues of existing metrics, we cast conditional coverage estimation as a classification problem. Conditio",
    "category": "Evaluation",
    "source": "arxiv",
    "score": 95,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "evaluation"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11779v1"
      }
    ],
    "source_file": "papers/weekly/2025-12-12-arxiv-conditional_coverage_diagnostics_for_conformal_prediction.yaml"
  },
  {
    "id": "2025-12-12-arxiv-agile_flight_emerges_from_multi_agent_competitive_racing",
    "date": "2025-12-12",
    "title": "Agile Flight Emerges from Multi-Agent Competitive Racing",
    "authors": "Vineet Pasumarti, Lorenzo Bianchi, Antonio Loquercio",
    "abstract": "Through multi-agent competition and the sparse high-level objective of winning a race, we find that both agile flight (e.g., high-speed motion pushing the platform to its physical limits) and strategy (e.g., overtaking or blocking) emerge from agents trained with reinforcement learning. We provide evidence in both simulation and the real world that this approach outperforms the common paradigm of training agents in isolation with rewards that prescribe behavior, e.g., progress on the raceline, i",
    "category": "Model",
    "source": "arxiv",
    "score": 95,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "model"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11781v1"
      }
    ],
    "source_file": "papers/weekly/2025-12-12-arxiv-agile_flight_emerges_from_multi_agent_competitive_racing.yaml"
  },
  {
    "id": "2025-12-12-arxiv-particulate_feed_forward_3d_object_articulation",
    "date": "2025-12-12",
    "title": "Particulate: Feed-Forward 3D Object Articulation",
    "authors": "Ruining Li, Yuxin Yao, Chuanxia Zheng, Christian Rupprecht, Joan Lasenby",
    "abstract": "We present Particulate, a feed-forward approach that, given a single static 3D mesh of an everyday object, directly infers all attributes of the underlying articulated structure, including its 3D parts, kinematic structure, and motion constraints. At its core is a transformer network, Part Articulation Transformer, which processes a point cloud of the input mesh using a flexible and scalable architecture to predict all the aforementioned attributes with native multi-joint support. We train the n",
    "category": "Model",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "model"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11798v1"
      }
    ],
    "source_file": "papers/weekly/2025-12-12-arxiv-particulate_feed_forward_3d_object_articulation.yaml"
  },
  {
    "id": "2025-12-12-arxiv-generative_parametric_design_gpd_a_framework_for_real_time_geometry_generation_a",
    "date": "2025-12-12",
    "title": "Generative Parametric Design (GPD): A framework for real-time geometry generation and on-the-fly multiparametric approximation",
    "authors": "Mohammed El Fallaki Idrissi, Jad Mounayer, Sebastian Rodriguez, Fodil Meraghni, Francisco Chinesta",
    "abstract": "This paper presents a novel paradigm in simulation-based engineering sciences by introducing a new framework called Generative Parametric Design (GPD). The GPD framework enables the generation of new designs along with their corresponding parametric solutions given as a reduced basis. To achieve this, two Rank Reduction Autoencoders (RRAEs) are employed, one for encoding and generating the design or geometry, and the other for encoding the sparse Proper Generalized Decomposition (sPGD) mode solu",
    "category": "Model",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "model"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11748v1"
      }
    ],
    "source_file": "papers/weekly/2025-12-12-arxiv-generative_parametric_design_gpd_a_framework_for_real_time_geometry_generation_a.yaml"
  },
  {
    "id": "2025-12-12-arxiv-medai_evaluating_txagent_s_therapeutic_agentic_reasoning_in_the_neurips_cure_ben",
    "date": "2025-12-12",
    "title": "MedAI: Evaluating TxAgent's Therapeutic Agentic Reasoning in the NeurIPS CURE-Bench Competition",
    "authors": "Tim Cofala, Christian Kalfar, Jingge Xiao, Johanna Schrader, Michelle Tang",
    "abstract": "Therapeutic decision-making in clinical medicine constitutes a high-stakes domain in which AI guidance interacts with complex interactions among patient characteristics, disease processes, and pharmacological agents. Tasks such as drug recommendation, treatment planning, and adverse-effect prediction demand robust, multi-step reasoning grounded in reliable biomedical knowledge. Agentic AI methods, exemplified by TxAgent, address these challenges through iterative retrieval-augmented generation (",
    "category": "Evaluation",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "evaluation"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11682v1"
      }
    ],
    "source_file": "papers/weekly/2025-12-12-arxiv-medai_evaluating_txagent_s_therapeutic_agentic_reasoning_in_the_neurips_cure_ben.yaml"
  },
  {
    "id": "2025-12-12-arxiv-smudged_fingerprints_a_systematic_evaluation_of_the_robustness_of_ai_image_finge",
    "date": "2025-12-12",
    "title": "Smudged Fingerprints: A Systematic Evaluation of the Robustness of AI Image Fingerprints",
    "authors": "Kai Yao, Marc Juarez",
    "abstract": "Model fingerprint detection techniques have emerged as a promising approach for attributing AI-generated images to their source models, but their robustness under adversarial conditions remains largely unexplored. We present the first systematic security evaluation of these techniques, formalizing threat models that encompass both white- and black-box access and two attack goals: fingerprint removal, which erases identifying traces to evade attribution, and fingerprint forgery, which seeks to ca",
    "category": "Incident",
    "source": "arxiv",
    "score": 90,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "incident"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11771v1"
      }
    ],
    "source_file": "papers/weekly/2025-12-12-arxiv-smudged_fingerprints_a_systematic_evaluation_of_the_robustness_of_ai_image_finge.yaml"
  },
  {
    "id": "2025-12-12-arxiv-from_verification_burden_to_trusted_collaboration_design_goals_for_llm_assisted",
    "date": "2025-12-12",
    "title": "From Verification Burden to Trusted Collaboration: Design Goals for LLM-Assisted Literature Reviews",
    "authors": "Brenda Nogueira, Werner Geyer, Andrew Anderson, Toby Jia-Jun Li, Dongwhi Kim",
    "abstract": "Large Language Models (LLMs) are increasingly embedded in academic writing practices. Although numerous studies have explored how researchers employ these tools for scientific writing, their concrete implementation, limitations, and design challenges within the literature review process remain underexplored. In this paper, we report a user study with researchers across multiple disciplines to characterize current practices, benefits, and \\textit{pain points} in using LLMs to investigate related ",
    "category": "Project",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "project"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11661v1"
      }
    ],
    "source_file": "papers/weekly/2025-12-12-arxiv-from_verification_burden_to_trusted_collaboration_design_goals_for_llm_assisted.yaml"
  },
  {
    "id": "2025-12-12-arxiv-from_signal_to_turn_interactional_friction_in_modular_speech_to_speech_pipelines",
    "date": "2025-12-12",
    "title": "From Signal to Turn: Interactional Friction in Modular Speech-to-Speech Pipelines",
    "authors": "Titaya Mairittha, Tanakon Sawanglok, Panuwit Raden, Jirapast Buntub, Thanapat Warunee",
    "abstract": "While voice-based AI systems have achieved remarkable generative capabilities, their interactions often feel conversationally broken. This paper examines the interactional friction that emerges in modular Speech-to-Speech Retrieval-Augmented Generation (S2S-RAG) pipelines. By analyzing a representative production system, we move beyond simple latency metrics to identify three recurring patterns of conversational breakdown: (1) Temporal Misalignment, where system delays violate user expectations ",
    "category": "Evaluation",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "evaluation"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11724v1"
      }
    ],
    "source_file": "papers/weekly/2025-W49/2025-12-12-arxiv-from_signal_to_turn_interactional_friction_in_modular_speech_to_speech_pipelines.yaml"
  },
  {
    "id": "2025-12-12-arxiv-cognisnn_enabling_neuron_expandability_pathway_reusability_and_dynamic_configura",
    "date": "2025-12-12",
    "title": "CogniSNN: Enabling Neuron-Expandability, Pathway-Reusability, and Dynamic-Configurability with Random Graph Architectures in Spiking Neural Networks",
    "authors": "Yongsheng Huang, Peibo Duan, Yujie Wu, Kai Sun, Zhipeng Liu",
    "abstract": "Spiking neural networks (SNNs), regarded as the third generation of artificial neural networks, are expected to bridge the gap between artificial intelligence and computational neuroscience. However, most mainstream SNN research directly adopts the rigid, chain-like hierarchical architecture of traditional artificial neural networks (ANNs), ignoring key structural characteristics of the brain. Biological neurons are stochastically interconnected, forming complex neural pathways that exhibit Neur",
    "category": "Hardware/Infra",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "hardware_infra"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11743v1"
      }
    ],
    "source_file": "papers/weekly/2025-W49/2025-12-12-arxiv-cognisnn_enabling_neuron_expandability_pathway_reusability_and_dynamic_configura.yaml"
  },
  {
    "id": "2025-12-12-arxiv-moment_based_3d_gaussian_splatting_resolving_volumetric_occlusion_with_order_ind",
    "date": "2025-12-12",
    "title": "Moment-Based 3D Gaussian Splatting: Resolving Volumetric Occlusion with Order-Independent Transmittance",
    "authors": "Jan U. Müller, Robin Tim Landsgesell, Leif Van Holland, Patrick Stotko, Reinhard Klein",
    "abstract": "The recent success of 3D Gaussian Splatting (3DGS) has reshaped novel view synthesis by enabling fast optimization and real-time rendering of high-quality radiance fields. However, it relies on simplified, order-dependent alpha blending and coarse approximations of the density integral within the rasterizer, thereby limiting its ability to render complex, overlapping semi-transparent objects. In this paper, we extend rasterization-based rendering of 3D Gaussian representations with a novel metho",
    "category": "Evaluation",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "evaluation"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11800v1"
      }
    ],
    "source_file": "papers/weekly/2025-W49/2025-12-12-arxiv-moment_based_3d_gaussian_splatting_resolving_volumetric_occlusion_with_order_ind.yaml"
  },
  {
    "id": "2025-12-12-arxiv-anchordream_repurposing_video_diffusion_for_embodiment_aware_robot_data_synthesi",
    "date": "2025-12-12",
    "title": "AnchorDream: Repurposing Video Diffusion for Embodiment-Aware Robot Data Synthesis",
    "authors": "Junjie Ye, Rong Xue, Basile Van Hoorick, Pavel Tokmakov, Muhammad Zubair Irshad",
    "abstract": "The collection of large-scale and diverse robot demonstrations remains a major bottleneck for imitation learning, as real-world data acquisition is costly and simulators offer limited diversity and fidelity with pronounced sim-to-real gaps. While generative models present an attractive solution, existing methods often alter only visual appearances without creating new behaviors, or suffer from embodiment inconsistencies that yield implausible motions. To address these limitations, we introduce A",
    "category": "Model",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "model"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11797v1"
      }
    ],
    "source_file": "papers/weekly/2025-W49/2025-12-12-arxiv-anchordream_repurposing_video_diffusion_for_embodiment_aware_robot_data_synthesi.yaml"
  },
  {
    "id": "2025-12-12-arxiv-reframing_music_driven_2d_dance_pose_generation_as_multi_channel_image_generatio",
    "date": "2025-12-12",
    "title": "Reframing Music-Driven 2D Dance Pose Generation as Multi-Channel Image Generation",
    "authors": "Yan Zhang, Han Zou, Lincong Feng, Cong Xie, Ruiqi Yu",
    "abstract": "Recent pose-to-video models can translate 2D pose sequences into photorealistic, identity-preserving dance videos, so the key challenge is to generate temporally coherent, rhythm-aligned 2D poses from music, especially under complex, high-variance in-the-wild distributions. We address this by reframing music-to-dance generation as a music-token-conditioned multi-channel image synthesis problem: 2D pose sequences are encoded as one-hot images, compressed by a pretrained image VAE, and modeled wit",
    "category": "Model",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "model"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11720v1"
      }
    ],
    "source_file": "papers/weekly/2025-W49/2025-12-12-arxiv-reframing_music_driven_2d_dance_pose_generation_as_multi_channel_image_generatio.yaml"
  },
  {
    "id": "2025-12-12-arxiv-mvise_a_visual_search_engine_for_analyzing_multiplex_ihc_brain_tissue_images",
    "date": "2025-12-12",
    "title": "mViSE: A Visual Search Engine for Analyzing Multiplex IHC Brain Tissue Images",
    "authors": "Liqiang Huang, Rachel W. Mills, Saikiran Mandula, Lin Bai, Mahtab Jeyhani",
    "abstract": "Whole-slide multiplex imaging of brain tissue generates massive information-dense images that are challenging to analyze and require custom software. We present an alternative query-driven programming-free strategy using a multiplex visual search engine (mViSE) that learns the multifaceted brain tissue chemoarchitecture, cytoarchitecture, and myeloarchitecture. Our divide-and-conquer strategy organizes the data into panels of related molecular markers and uses self-supervised learning to train a",
    "category": "Model",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "model"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11745v1"
      }
    ],
    "source_file": "papers/weekly/2025-W49/2025-12-12-arxiv-mvise_a_visual_search_engine_for_analyzing_multiplex_ihc_brain_tissue_images.yaml"
  },
  {
    "id": "2025-12-12-arxiv-super_suffixes_bypassing_text_generation_alignment_and_guard_models_simultaneous",
    "date": "2025-12-12",
    "title": "Super Suffixes: Bypassing Text Generation Alignment and Guard Models Simultaneously",
    "authors": "Andrew Adiletta, Kathryn Adiletta, Kemal Derya, Berk Sunar",
    "abstract": "The rapid deployment of Large Language Models (LLMs) has created an urgent need for enhanced security and privacy measures in Machine Learning (ML). LLMs are increasingly being used to process untrusted text inputs and even generate executable code, often while having access to sensitive system controls. To address these security concerns, several companies have introduced guard models, which are smaller, specialized models designed to protect text generation models from adversarial or malicious",
    "category": "Incident",
    "source": "arxiv",
    "score": 95,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "incident"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11783v1"
      }
    ],
    "source_file": "papers/weekly/2025-W49/2025-12-12-arxiv-super_suffixes_bypassing_text_generation_alignment_and_guard_models_simultaneous.yaml"
  },
  {
    "id": "2025-12-12-arxiv-editmgt_unleashing_potentials_of_masked_generative_transformers_in_image_editing",
    "date": "2025-12-12",
    "title": "EditMGT: Unleashing Potentials of Masked Generative Transformers in Image Editing",
    "authors": "Wei Chow, Linfeng Li, Lingdong Kong, Zefeng Li, Qi Xu",
    "abstract": "Recent advances in diffusion models (DMs) have achieved exceptional visual quality in image editing tasks. However, the global denoising dynamics of DMs inherently conflate local editing targets with the full-image context, leading to unintended modifications in non-target regions. In this paper, we shift our attention beyond DMs and turn to Masked Generative Transformers (MGTs) as an alternative approach to tackle this challenge. By predicting multiple masked tokens rather than holistic refinem",
    "category": "Model",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "model"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11715v1"
      }
    ],
    "source_file": "papers/weekly/2025-W49/2025-12-12-arxiv-editmgt_unleashing_potentials_of_masked_generative_transformers_in_image_editing.yaml"
  },
  {
    "id": "2025-12-12-nature-deciphering_rna_ligand_binding_specificity_with_gerna_bind",
    "date": "2025-12-12",
    "title": "Deciphering RNA–ligand binding specificity with GerNA-Bind",
    "authors": "Yunpeng Xia, Jiayi Li, Yi-Ting Chu, Jiahua Rao, Jing Chen",
    "abstract": "<p>Nature Machine Intelligence, Published online: 12 December 2025; <a href=\"https://www.nature.com/articles/s42256-025-01154-z\">doi:10.1038/s42256-025-01154-z</a></p>Xia et al. introduce GerNA-Bind, a geometric deep learning framework designed to predict RNA–ligand binding specificity by integrating multistate RNA–ligand interactions.",
    "category": "Model",
    "source": "nature",
    "score": 115,
    "tags": [
      "ai",
      "research",
      "nature",
      "model"
    ],
    "links": [
      {
        "title": "View Paper",
        "url": "https://www.nature.com/articles/s42256-025-01154-z"
      },
      {
        "title": "DOI",
        "url": "https://doi.org/10.1038/s42256-025-01154-z"
      }
    ],
    "source_file": "papers/weekly/2025-W49/2025-12-12-nature-deciphering_rna_ligand_binding_specificity_with_gerna_bind.yaml"
  },
  {
    "id": "2025-12-12-arxiv-conditional_coverage_diagnostics_for_conformal_prediction",
    "date": "2025-12-12",
    "title": "Conditional Coverage Diagnostics for Conformal Prediction",
    "authors": "Sacha Braun, David Holzmüller, Michael I. Jordan, Francis Bach",
    "abstract": "Evaluating conditional coverage remains one of the most persistent challenges in assessing the reliability of predictive systems. Although conformal methods can give guarantees on marginal coverage, no method can guarantee to produce sets with correct conditional coverage, leaving practitioners without a clear way to interpret local deviations. To overcome sample-inefficiency and overfitting issues of existing metrics, we cast conditional coverage estimation as a classification problem. Conditio",
    "category": "Evaluation",
    "source": "arxiv",
    "score": 95,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "evaluation"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11779v1"
      }
    ],
    "source_file": "papers/weekly/2025-W49/2025-12-12-arxiv-conditional_coverage_diagnostics_for_conformal_prediction.yaml"
  },
  {
    "id": "2025-12-12-nature-llm_use_in_scholarly_writing_poses_a_provenance_problem",
    "date": "2025-12-12",
    "title": "LLM use in scholarly writing poses a provenance problem",
    "authors": "Brian D. Earp, Haotian Yuan, Julian Koplin, Sebastian Porsdam Mann",
    "abstract": "<p>Nature Machine Intelligence, Published online: 12 December 2025; <a href=\"https://www.nature.com/articles/s42256-025-01159-8\">doi:10.1038/s42256-025-01159-8</a></p>LLM use in scholarly writing poses a provenance problem",
    "category": "Model",
    "source": "nature",
    "score": 110,
    "tags": [
      "ai",
      "research",
      "nature",
      "model"
    ],
    "links": [
      {
        "title": "View Paper",
        "url": "https://www.nature.com/articles/s42256-025-01159-8"
      },
      {
        "title": "DOI",
        "url": "https://doi.org/10.1038/s42256-025-01159-8"
      }
    ],
    "source_file": "papers/weekly/2025-W49/2025-12-12-nature-llm_use_in_scholarly_writing_poses_a_provenance_problem.yaml"
  },
  {
    "id": "2025-12-12-arxiv-agile_flight_emerges_from_multi_agent_competitive_racing",
    "date": "2025-12-12",
    "title": "Agile Flight Emerges from Multi-Agent Competitive Racing",
    "authors": "Vineet Pasumarti, Lorenzo Bianchi, Antonio Loquercio",
    "abstract": "Through multi-agent competition and the sparse high-level objective of winning a race, we find that both agile flight (e.g., high-speed motion pushing the platform to its physical limits) and strategy (e.g., overtaking or blocking) emerge from agents trained with reinforcement learning. We provide evidence in both simulation and the real world that this approach outperforms the common paradigm of training agents in isolation with rewards that prescribe behavior, e.g., progress on the raceline, i",
    "category": "Model",
    "source": "arxiv",
    "score": 95,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "model"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11781v1"
      }
    ],
    "source_file": "papers/weekly/2025-W49/2025-12-12-arxiv-agile_flight_emerges_from_multi_agent_competitive_racing.yaml"
  },
  {
    "id": "2025-12-12-arxiv-particulate_feed_forward_3d_object_articulation",
    "date": "2025-12-12",
    "title": "Particulate: Feed-Forward 3D Object Articulation",
    "authors": "Ruining Li, Yuxin Yao, Chuanxia Zheng, Christian Rupprecht, Joan Lasenby",
    "abstract": "We present Particulate, a feed-forward approach that, given a single static 3D mesh of an everyday object, directly infers all attributes of the underlying articulated structure, including its 3D parts, kinematic structure, and motion constraints. At its core is a transformer network, Part Articulation Transformer, which processes a point cloud of the input mesh using a flexible and scalable architecture to predict all the aforementioned attributes with native multi-joint support. We train the n",
    "category": "Model",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "model"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11798v1"
      }
    ],
    "source_file": "papers/weekly/2025-W49/2025-12-12-arxiv-particulate_feed_forward_3d_object_articulation.yaml"
  },
  {
    "id": "2025-12-12-arxiv-generative_parametric_design_gpd_a_framework_for_real_time_geometry_generation_a",
    "date": "2025-12-12",
    "title": "Generative Parametric Design (GPD): A framework for real-time geometry generation and on-the-fly multiparametric approximation",
    "authors": "Mohammed El Fallaki Idrissi, Jad Mounayer, Sebastian Rodriguez, Fodil Meraghni, Francisco Chinesta",
    "abstract": "This paper presents a novel paradigm in simulation-based engineering sciences by introducing a new framework called Generative Parametric Design (GPD). The GPD framework enables the generation of new designs along with their corresponding parametric solutions given as a reduced basis. To achieve this, two Rank Reduction Autoencoders (RRAEs) are employed, one for encoding and generating the design or geometry, and the other for encoding the sparse Proper Generalized Decomposition (sPGD) mode solu",
    "category": "Model",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "model"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11748v1"
      }
    ],
    "source_file": "papers/weekly/2025-W49/2025-12-12-arxiv-generative_parametric_design_gpd_a_framework_for_real_time_geometry_generation_a.yaml"
  },
  {
    "id": "2025-12-12-arxiv-uncertainty_aware_domain_adaptation_for_vitiligo_segmentation_in_clinical_photog",
    "date": "2025-12-12",
    "title": "Uncertainty-Aware Domain Adaptation for Vitiligo Segmentation in Clinical Photographs",
    "authors": "Wentao Jiang, Vamsi Varra, Caitlin Perez-Stable, Harrison Zhu, Meredith Apicella",
    "abstract": "Accurately quantifying vitiligo extent in routine clinical photographs is crucial for longitudinal monitoring of treatment response. We propose a trustworthy, frequency-aware segmentation framework built on three synergistic pillars: (1) a data-efficient training strategy combining domain-adaptive pre-training on the ISIC 2019 dataset with an ROI-constrained dual-task loss to suppress background noise; (2) an architectural refinement via a ConvNeXt V2-based encoder enhanced with a novel High-Fre",
    "category": "Model",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "model"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11791v1"
      }
    ],
    "source_file": "papers/weekly/2025-W49/2025-12-12-arxiv-uncertainty_aware_domain_adaptation_for_vitiligo_segmentation_in_clinical_photog.yaml"
  },
  {
    "id": "2025-12-12-arxiv-medai_evaluating_txagent_s_therapeutic_agentic_reasoning_in_the_neurips_cure_ben",
    "date": "2025-12-12",
    "title": "MedAI: Evaluating TxAgent's Therapeutic Agentic Reasoning in the NeurIPS CURE-Bench Competition",
    "authors": "Tim Cofala, Christian Kalfar, Jingge Xiao, Johanna Schrader, Michelle Tang",
    "abstract": "Therapeutic decision-making in clinical medicine constitutes a high-stakes domain in which AI guidance interacts with complex interactions among patient characteristics, disease processes, and pharmacological agents. Tasks such as drug recommendation, treatment planning, and adverse-effect prediction demand robust, multi-step reasoning grounded in reliable biomedical knowledge. Agentic AI methods, exemplified by TxAgent, address these challenges through iterative retrieval-augmented generation (",
    "category": "Evaluation",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "evaluation"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11682v1"
      }
    ],
    "source_file": "papers/weekly/2025-W49/2025-12-12-arxiv-medai_evaluating_txagent_s_therapeutic_agentic_reasoning_in_the_neurips_cure_ben.yaml"
  },
  {
    "id": "2025-12-12-arxiv-v_rgbx_video_editing_with_accurate_controls_over_intrinsic_properties",
    "date": "2025-12-12",
    "title": "V-RGBX: Video Editing with Accurate Controls over Intrinsic Properties",
    "authors": "Ye Fang, Tong Wu, Valentin Deschaintre, Duygu Ceylan, Iliyan Georgiev",
    "abstract": "Large-scale video generation models have shown remarkable potential in modeling photorealistic appearance and lighting interactions in real-world scenes. However, a closed-loop framework that jointly understands intrinsic scene properties (e.g., albedo, normal, material, and irradiance), leverages them for video synthesis, and supports editable intrinsic representations remains unexplored. We present V-RGBX, the first end-to-end framework for intrinsic-aware video editing. V-RGBX unifies three k",
    "category": "Industry",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "industry"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11799v1"
      }
    ],
    "source_file": "papers/weekly/2025-W49/2025-12-12-arxiv-v_rgbx_video_editing_with_accurate_controls_over_intrinsic_properties.yaml"
  },
  {
    "id": "2025-12-12-arxiv-structure_from_tracking_distilling_structure_preserving_motion_for_video_generat",
    "date": "2025-12-12",
    "title": "Structure From Tracking: Distilling Structure-Preserving Motion for Video Generation",
    "authors": "Yang Fei, George Stoica, Jingyuan Liu, Qifeng Chen, Ranjay Krishna",
    "abstract": "Reality is a dance between rigid constraints and deformable structures. For video models, that means generating motion that preserves fidelity as well as structure. Despite progress in diffusion models, producing realistic structure-preserving motion remains challenging, especially for articulated and deformable objects such as humans and animals. Scaling training data alone, so far, has failed to resolve physically implausible transitions. Existing approaches rely on conditioning with noisy mot",
    "category": "Model",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "model"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11792v1"
      }
    ],
    "source_file": "papers/weekly/2025-W49/2025-12-12-arxiv-structure_from_tracking_distilling_structure_preserving_motion_for_video_generat.yaml"
  },
  {
    "id": "2025-12-12-arxiv-weak_to_strong_generalization_enables_fully_automated_de_novo_training_of_multi",
    "date": "2025-12-12",
    "title": "Weak-to-Strong Generalization Enables Fully Automated De Novo Training of Multi-head Mask-RCNN Model for Segmenting Densely Overlapping Cell Nuclei in Multiplex Whole-slice Brain Images",
    "authors": "Lin Bai, Xiaoyang Li, Liqiang Huang, Quynh Nguyen, Hien Van Nguyen",
    "abstract": "We present a weak to strong generalization methodology for fully automated training of a multi-head extension of the Mask-RCNN method with efficient channel attention for reliable segmentation of overlapping cell nuclei in multiplex cyclic immunofluorescent (IF) whole-slide images (WSI), and present evidence for pseudo-label correction and coverage expansion, the key phenomena underlying weak to strong generalization. This method can learn to segment de novo a new class of images from a new inst",
    "category": "Model",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "model"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11722v1"
      }
    ],
    "source_file": "papers/weekly/2025-W49/2025-12-12-arxiv-weak_to_strong_generalization_enables_fully_automated_de_novo_training_of_multi.yaml"
  },
  {
    "id": "2025-12-12-arxiv-svg_t2i_scaling_up_text_to_image_latent_diffusion_model_without_variational_auto",
    "date": "2025-12-12",
    "title": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder",
    "authors": "Minglei Shi, Haolin Wang, Borui Zhang, Wenzhao Zheng, Bohan Zeng",
    "abstract": "Visual generation grounded in Visual Foundation Model (VFM) representations offers a highly promising unified pathway for integrating visual understanding, perception, and generation. Despite this potential, training large-scale text-to-image diffusion models entirely within the VFM representation space remains largely unexplored. To bridge this gap, we scale the SVG (Self-supervised representations for Visual Generation) framework, proposing SVG-T2I to support high-quality text-to-image synthes",
    "category": "Model",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "model"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11749v1"
      }
    ],
    "source_file": "papers/weekly/2025-W49/2025-12-12-arxiv-svg_t2i_scaling_up_text_to_image_latent_diffusion_model_without_variational_auto.yaml"
  },
  {
    "id": "2025-12-12-arxiv-smudged_fingerprints_a_systematic_evaluation_of_the_robustness_of_ai_image_finge",
    "date": "2025-12-12",
    "title": "Smudged Fingerprints: A Systematic Evaluation of the Robustness of AI Image Fingerprints",
    "authors": "Kai Yao, Marc Juarez",
    "abstract": "Model fingerprint detection techniques have emerged as a promising approach for attributing AI-generated images to their source models, but their robustness under adversarial conditions remains largely unexplored. We present the first systematic security evaluation of these techniques, formalizing threat models that encompass both white- and black-box access and two attack goals: fingerprint removal, which erases identifying traces to evade attribution, and fingerprint forgery, which seeks to ca",
    "category": "Incident",
    "source": "arxiv",
    "score": 90,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "incident"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11771v1"
      }
    ],
    "source_file": "papers/weekly/2025-W49/2025-12-12-arxiv-smudged_fingerprints_a_systematic_evaluation_of_the_robustness_of_ai_image_finge.yaml"
  },
  {
    "id": "2025-12-12-arxiv-from_verification_burden_to_trusted_collaboration_design_goals_for_llm_assisted",
    "date": "2025-12-12",
    "title": "From Verification Burden to Trusted Collaboration: Design Goals for LLM-Assisted Literature Reviews",
    "authors": "Brenda Nogueira, Werner Geyer, Andrew Anderson, Toby Jia-Jun Li, Dongwhi Kim",
    "abstract": "Large Language Models (LLMs) are increasingly embedded in academic writing practices. Although numerous studies have explored how researchers employ these tools for scientific writing, their concrete implementation, limitations, and design challenges within the literature review process remain underexplored. In this paper, we report a user study with researchers across multiple disciplines to characterize current practices, benefits, and \\textit{pain points} in using LLMs to investigate related ",
    "category": "Project",
    "source": "arxiv",
    "score": 100,
    "tags": [
      "ai",
      "research",
      "arxiv",
      "project"
    ],
    "links": [
      {
        "title": "PDF",
        "url": "https://arxiv.org/pdf/2512.11661v1"
      }
    ],
    "source_file": "papers/weekly/2025-W49/2025-12-12-arxiv-from_verification_burden_to_trusted_collaboration_design_goals_for_llm_assisted.yaml"
  },
  {
    "id": "2025-12-10-nature-a_multimodal_cell_free_rna_language_model_for_liquid_biopsy_applications",
    "date": "2025-12-10",
    "title": "A multimodal cell-free RNA language model for liquid biopsy applications",
    "authors": "Mehran Karimzadeh, Aiden M. Sababi, Amir Momen-Roknabadi, Nae-Chyun Chen, Taylor B. Cavazos",
    "abstract": "<p>Nature Machine Intelligence, Published online: 10 December 2025; <a href=\"https://www.nature.com/articles/s42256-025-01148-x\">doi:10.1038/s42256-025-01148-x</a></p>Exai-1, a cell-free RNA foundation model that integrates sequence, structure and expression features, advances liquid biopsy diagnostics by denoising noisy data, augmenting limited datasets and improving the generalizability of cancer detection models.",
    "category": "Model",
    "source": "nature",
    "score": 115,
    "tags": [
      "ai",
      "research",
      "nature",
      "model"
    ],
    "links": [
      {
        "title": "View Paper",
        "url": "https://www.nature.com/articles/s42256-025-01148-x"
      },
      {
        "title": "DOI",
        "url": "https://doi.org/10.1038/s42256-025-01148-x"
      }
    ],
    "source_file": "papers/weekly/2025-W49/2025-12-10-nature-a_multimodal_cell_free_rna_language_model_for_liquid_biopsy_applications.yaml"
  },
  {
    "id": "2025-12-09-nature-actor_critic_networks_with_analogue_memristors_mimicking_reward_based_learning",
    "date": "2025-12-09",
    "title": "Actor–critic networks with analogue memristors mimicking reward-based learning",
    "authors": "Kevin Portner, Till Zellweger, Flavio Martinelli, Laura Bégon-Lours, Valeria Bragaglia",
    "abstract": "<p>Nature Machine Intelligence, Published online: 09 December 2025; <a href=\"https://www.nature.com/articles/s42256-025-01149-w\">doi:10.1038/s42256-025-01149-w</a></p>A framework based on actor–critic temporal difference learning and employing a biologically plausible network architecture that mimics reward-based learning on memristors and enables full in-memory training for navigation tasks is discussed.",
    "category": "Model",
    "source": "nature",
    "score": 115,
    "tags": [
      "ai",
      "research",
      "nature",
      "model"
    ],
    "links": [
      {
        "title": "View Paper",
        "url": "https://www.nature.com/articles/s42256-025-01149-w"
      },
      {
        "title": "DOI",
        "url": "https://doi.org/10.1038/s42256-025-01149-w"
      }
    ],
    "source_file": "papers/weekly/2025-W49/2025-12-09-nature-actor_critic_networks_with_analogue_memristors_mimicking_reward_based_learning.yaml"
  },
  {
    "id": "2025-12-09-nature-fully_analogue_reinforcement_learning_with_memristors",
    "date": "2025-12-09",
    "title": "Fully analogue reinforcement learning with memristors",
    "authors": "Yue Zhang, Xiaojuan Qi, Zhongrui Wang",
    "abstract": "<p>Nature Machine Intelligence, Published online: 09 December 2025; <a href=\"https://www.nature.com/articles/s42256-025-01157-w\">doi:10.1038/s42256-025-01157-w</a></p>Reinforcement learning has a key role in artifical intelligence (AI), but its implementation on neuromorphic hardware typically involves operations executed on conventional digital computers. A study now addresses this issue by implementing an actor–critic network fully in hardware using analogue memristors.",
    "category": "Model",
    "source": "nature",
    "score": 110,
    "tags": [
      "ai",
      "research",
      "nature",
      "model"
    ],
    "links": [
      {
        "title": "View Paper",
        "url": "https://www.nature.com/articles/s42256-025-01157-w"
      },
      {
        "title": "DOI",
        "url": "https://doi.org/10.1038/s42256-025-01157-w"
      }
    ],
    "source_file": "papers/weekly/2025-W49/2025-12-09-nature-fully_analogue_reinforcement_learning_with_memristors.yaml"
  }
]