{
  "key_insight": "Resampling Forcing is a teacher-free, self-resampling training scheme that closes the train–test gap in autoregressive video diffusion models, enabling stable end-to-end training from scratch and at scale.",
  "problem_solved": "Autoregressive video diffusion models suffer from exposure bias due to a train–test mismatch (training on ground-truth context but generating from model predictions). Prior fixes use separate teacher models or online discriminators; this paper removes that dependency with an integrated, teacher-free solution.",
  "method": [
    "Self-resampling during training: randomly replace conditioning frames with the model's own noisy/reconstructed predictions to mimic test-time autoregressive inputs.",
    "Resampling Forcing objective: incorporate resampled contexts into the diffusion loss so the model learns to recover from its own mistakes without a teacher/discriminator.",
    "Scalable end-to-end setup: apply the scheme across long video sequences and train autoregressive diffusion models from scratch without auxiliary supervision."
  ],
  "impact": "Makes autoregressive video diffusion models more robust and simpler to train by eliminating external teacher models or discriminators, improving realism and reliability of long-horizon video prediction and simulation. Practitioners get a scalable, end-to-end recipe for reducing exposure bias.",
  "visual_elements": [
    "Side-by-side diagram: training (ground-truth conditioning) vs. test (autoregressive prediction) showing the exposure bias gap.",
    "Flowchart of Resampling Forcing: how self-resampling inserts model predictions into conditioning frames and feeds them back into the diffusion loss.",
    "Metric bar/line chart: performance comparison (e.g., fidelity/consistency) of baseline autoregressive diffusion with teacher/discriminator vs. Resampling Forcing.",
    "Sequence illustration: example video frames showing progressive resampling and recovery of errors during generation."
  ],
  "hashtags": [
    "#VideoDiffusion",
    "#AutoregressiveModels",
    "#SelfResampling",
    "#ExposureBias",
    "#GenerativeAI"
  ],
  "paper_id": "2025-12-17-arxiv-end_to_end_training_for_autoregressive_video_diffusion_via_self_resampling",
  "paper_title": "End-to-End Training for Autoregressive Video Diffusion via Self-Resampling",
  "paper_category": "Model",
  "paper_date": "2025-12-17",
  "paper_authors": "Yuwei Guo, Ceyuan Yang, Hao He, Yang Zhao, Meng Wei",
  "paper_links": [
    {
      "title": "PDF",
      "url": "https://arxiv.org/pdf/2512.15702v1"
    }
  ],
  "generated_at": "2025-12-18T22:17:22.929848"
}