{
  "key_insight": "Use LLMs to synthesize and iteratively search small, deployable heuristics that are tuned to the exact workload and hardware, producing instance‑optimal resource‑management policies automatically.",
  "problem_solved": "Hand‑designed heuristics for scheduling, caching, and AQM are costly to create and quickly become suboptimal as workloads and hardware change; this work automates producing high‑performing, specialized heuristics for each deployment.",
  "method": [
    "Represent heuristics as compact, executable templates/programs and prompt an LLM to propose candidate heuristics.",
    "Evaluate candidates empirically on the target workload and hardware (simulate/bench), score them, and use a search loop to refine proposals toward instance‑optimal behavior.",
    "Constrain synthesis for safety/performance (cost limits, resource bounds) and produce lightweight heuristics suitable for real systems deployment."
  ],
  "impact": "AI/ML practitioners get automated, workload‑specific system policies that improve resource efficiency and application performance without manual tuning, shortening deployment cycles and adapting to changing hardware and workloads.",
  "visual_elements": [
    "Pipeline diagram: LLM → generate candidate heuristics → run benchmarks on target hardware/workload → score → iterate.",
    "Bar chart comparing performance (latency/throughput/resource usage) of hand‑tuned heuristic vs. Vulcan's instance‑optimal heuristic across several workloads.",
    "Heatmap or matrix showing per‑workload/hardware gains (darker = bigger improvement) to illustrate instance specificity.",
    "Inset showing a short example of a synthesized heuristic (pseudo‑code) and its runtime footprint (bytes/CPU)"
  ],
  "hashtags": [
    "#SystemsAI",
    "#LLMSynthesis",
    "#ResourceManagement",
    "#InstanceOptimal",
    "#HeuristicAutomation"
  ],
  "paper_id": "2025-12-31-arxiv-vulcan_instance_optimal_systems_heuristics_through_llm_driven_search",
  "paper_title": "Vulcan: Instance-Optimal Systems Heuristics Through LLM-Driven Search",
  "paper_category": "Hardware/Infra",
  "paper_date": "2025-12-31",
  "paper_authors": "Rohit Dwivedula, Divyanshu Saxena, Sujay Yadalam, Daehyeok Kim, Aditya Akella",
  "paper_links": [
    {
      "title": "PDF",
      "url": "https://arxiv.org/pdf/2512.25065v1"
    }
  ],
  "generated_at": "2026-01-01T06:21:37.392484"
}