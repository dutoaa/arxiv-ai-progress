{
  "key_insight": "State-of-the-art vision-language models show a strong popularity/memorization bias—achieving up to 34% higher accuracy on famous buildings than ordinary ones—revealing reliance on memorized iconic examples rather than generalizable understanding.",
  "problem_solved": "Identifies and quantifies popularity bias in VLMs and provides a large, standardized benchmark to evaluate ordinal prediction performance across famous vs. ordinary buildings.",
  "method": [
    "Curate YearGuessr: a 55,546-image, multi-modal dataset spanning 157 countries with continuous ordinal labels (e.g., build year) and rich metadata.",
    "Formulate an ordinal regression benchmark and evaluate popular VLMs to measure performance gaps between famous and non-famous structures.",
    "Analyze sources of bias using controlled splits and metrics that expose memorization vs. generalization."
  ],
  "impact": "Provides practitioners a concrete dataset and evaluation protocol to detect popularity-driven failure modes in VLMs, enabling more robust model development, fairer benchmarks, and targeted debiasing strategies.",
  "visual_elements": [
    "Bar chart comparing accuracy on famous vs. ordinary buildings (showing the ~34% gap)",
    "World map heatmap of dataset coverage across 157 countries with sample icons",
    "Pipeline diagram: dataset → ordinal regression benchmark → evaluation metrics highlighting bias",
    "Before/after image pairs (famous vs. ordinary) annotated with model predictions and confidence to illustrate memorization"
  ],
  "hashtags": [
    "#PopularityBias",
    "#VisionLanguage",
    "#OrdinalRegression",
    "#Dataset",
    "#FairAI"
  ],
  "paper_id": "2025-12-24-arxiv-beyond_memorization_a_multi_modal_ordinal_regression_benchmark_to_expose_popular",
  "paper_title": "Beyond Memorization: A Multi-Modal Ordinal Regression Benchmark to Expose Popularity Bias in Vision-Language Models",
  "paper_category": "Evaluation",
  "paper_date": "2025-12-24",
  "paper_authors": "Li-Zhong Szu-Tu, Ting-Lin Wu, Chia-Jui Chang, He Syu, Yu-Lun Liu",
  "paper_links": [
    {
      "title": "PDF",
      "url": "https://arxiv.org/pdf/2512.21337v1"
    }
  ],
  "generated_at": "2025-12-26T06:23:33.513912"
}