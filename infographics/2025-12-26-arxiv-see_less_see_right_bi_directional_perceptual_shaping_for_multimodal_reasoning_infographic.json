{
  "key_insight": "BiPS converts question-conditioned masked views into bidirectional where-to-look signals that guide both perception and reasoning, enabling VLMs to capture fine-grained visual evidence (e.g., chart polylines) more robustly and efficiently.",
  "problem_solved": "Addresses VLMs' inability to reliably use fine-grained visual cues, poor cross-domain generalization of intermediate visual hints, and high inference-time cost from external/latent visual toolchains.",
  "method": [
    "Generate question-conditioned masked visual views that focus on candidate regions relevant to the query.",
    "Produce bidirectional where-to-look signals that shape both the visual encoder (what to perceive) and the reasoning module (what to use), creating tighter perception–reasoning feedback.",
    "Design a lightweight integration that reduces dependency on heavy external tools or large latent token sets, improving inference efficiency and robustness to domain shifts."
  ],
  "impact": "Enables more accurate and efficient multimodal reasoning by surfacing fine-grained visual evidence and aligning perception with downstream reasoning—useful for chart understanding, VQA, and other vision-language tasks where detail and speed matter.",
  "visual_elements": [
    "Pipeline diagram: question -> masked view generator -> bidirectional where-to-look signals -> perception & reasoning modules",
    "Before/after comparison on a chart: missed polylines vs. recovered fine-grained evidence highlighted",
    "Heatmap overlays showing bidirectional attention maps (perception-focused and reasoning-focused) on an image",
    "Bar chart comparing inference latency and accuracy/robustness across domains (baseline vs. BiPS)"
  ],
  "hashtags": [
    "#VisionLanguage",
    "#MultimodalAI",
    "#PerceptualShaping",
    "#EfficientAI",
    "#VisualReasoning"
  ],
  "paper_id": "2025-12-26-arxiv-see_less_see_right_bi_directional_perceptual_shaping_for_multimodal_reasoning",
  "paper_title": "See Less, See Right: Bi-directional Perceptual Shaping For Multimodal Reasoning",
  "paper_category": "Model",
  "paper_date": "2025-12-26",
  "paper_authors": "Shuoshuo Zhang, Yizhen Zhang, Jingjing Fu, Lei Song, Jiang Bian",
  "paper_links": [
    {
      "title": "PDF",
      "url": "https://arxiv.org/pdf/2512.22120v1"
    }
  ],
  "generated_at": "2026-01-03T06:23:24.547268"
}