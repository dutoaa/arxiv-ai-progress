{
  "key_insight": "Large language models can drive a focused search loop that synthesizes instance‑optimal, deployable heuristics tailored to a specific workload and hardware, automating and outperforming manually engineered rules.",
  "problem_solved": "Eliminates the costly, brittle process of hand‑designing and continuously re‑tuning systems heuristics (scheduling, caching, AQM, etc.) as hardware and workloads change, which often yields suboptimal performance.",
  "method": [
    "Prompt an LLM to generate candidate heuristic implementations (pseudo-code or parameterized policies) conditioned on workload and hardware profiles.",
    "Evaluate candidates via fast simulation or real measurements and score them by per‑instance performance to find instance‑optimal variants.",
    "Iteratively refine prompts/solutions using feedback from evaluations until a high‑performing, deployable heuristic is synthesized."
  ],
  "impact": "Automates heuristic design and tuning, cutting engineering effort and delivering higher throughput/ lower latency for ML training and serving across diverse hardware — making system-level optimizations accessible and reproducible for AI teams.",
  "visual_elements": [
    "Flowchart of the LLM-driven search loop: profile → LLM generates heuristics → evaluate → feedback → repeat",
    "Before vs after bar chart showing performance (throughput/latency/resource utilization) comparing hand‑tuned vs Vulcan‑synthesized heuristics",
    "Heatmap or scatter showing per-instance gains across different workloads and hardware configurations",
    "Iconic illustration of generated pseudocode turning into deployable code (LLM output → simulator → production)"
  ],
  "hashtags": [
    "#SystemsResearch",
    "#LLMforSystems",
    "#AutoTuning",
    "#ResourceManagement",
    "#Heuristics"
  ],
  "paper_id": "2025-12-31-arxiv-vulcan_instance_optimal_systems_heuristics_through_llm_driven_search",
  "paper_title": "Vulcan: Instance-Optimal Systems Heuristics Through LLM-Driven Search",
  "paper_category": "Hardware/Infra",
  "paper_date": "2025-12-31",
  "paper_authors": "Rohit Dwivedula, Divyanshu Saxena, Sujay Yadalam, Daehyeok Kim, Aditya Akella",
  "paper_links": [
    {
      "title": "PDF",
      "url": "https://arxiv.org/pdf/2512.25065v1"
    }
  ],
  "generated_at": "2026-01-02T06:22:04.531099"
}