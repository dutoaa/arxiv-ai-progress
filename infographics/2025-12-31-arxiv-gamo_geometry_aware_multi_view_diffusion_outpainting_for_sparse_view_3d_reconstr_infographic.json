{
  "key_insight": "GaMO uses a geometry-aware, multi-view diffusion outpainting model to synthesize novel, geometry-consistent views from sparse inputs, enabling substantially better 3D reconstruction when only a few camera views are available.",
  "problem_solved": "Improves reconstruction quality for sparse-view 3D capture by generating additional, multi-view-consistent imagery that fills in missing viewpoints and geometric coverage.",
  "method": [
    "Geometry-conditioned diffusion outpainting: a diffusion generator conditioned on input images and camera poses to synthesize novel views consistent with scene geometry.",
    "Multi-view geometric constraints: enforce epipolar/pose/depth consistency during generation (e.g., re-projection, depth-aware losses) so synthesized views align with real views.",
    "Augmentation-for-reconstruction: use the synthesized views to augment downstream 3D reconstruction (neural rendering / volumetric fusion), boosting fidelity from sparse inputs."
  ],
  "impact": "Allows AI/ML practitioners to obtain high-quality 3D models with far fewer input images, lowering data-collection costs and improving workflows in AR/VR, robotics, and cultural heritage digitization.",
  "visual_elements": [
    "Pipeline diagram: sparse input views + camera poses → geometry-aware diffusion outpainting → augmented view set → 3D reconstruction",
    "Before/after reconstruction comparison: sparse-only vs GaMO-augmented 3D meshes or renderings",
    "Schematic of geometric constraints: camera frustums, epipolar lines, and depth re-projection arrows showing consistency checks",
    "Bar/line chart: reconstruction metrics (e.g., IoU, Chamfer, PSNR) comparing GaMO to baseline methods across varying view counts"
  ],
  "hashtags": [
    "#3DReconstruction",
    "#DiffusionModels",
    "#MultiView",
    "#GeometryAware",
    "#ComputerVision"
  ],
  "paper_id": "2025-12-31-arxiv-gamo_geometry_aware_multi_view_diffusion_outpainting_for_sparse_view_3d_reconstr",
  "paper_title": "GaMO: Geometry-aware Multi-view Diffusion Outpainting for Sparse-View 3D Reconstruction",
  "paper_category": "Model",
  "paper_date": "2025-12-31",
  "paper_authors": "Yi-Chuan Huang, Hao-Jen Chien, Chin-Yang Lin, Ying-Huan Chen, Yu-Lun Liu",
  "paper_links": [
    {
      "title": "PDF",
      "url": "https://arxiv.org/pdf/2512.25073v1"
    }
  ],
  "generated_at": "2026-01-03T06:21:13.958695"
}