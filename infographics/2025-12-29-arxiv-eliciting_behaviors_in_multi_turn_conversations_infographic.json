{
  "key_insight": "This paper extends behavior elicitation techniques from single-turn prompts to realistic multi-turn conversations and introduces an analytical framework that categorizes existing methods into three families, revealing how conversational context changes what prompts elicit. It shows that multi-turn dynamics materially affect the success and design of elicitation strategies.",
  "problem_solved": "How to identify and reliably induce specific, often complex behaviors from large language models in multi-turn conversational settingsâ€”where single-turn prompting techniques fall short.",
  "method": [
    "Propose an analytical framework that organizes existing elicitation methods into three families (classification, comparison, and iterative/conversational strategies) to clarify their assumptions and failure modes in multi-turn contexts.",
    "Adapt and apply existing prompting and search techniques to multi-turn dialogues, investigating how conversation history, turn ordering, and scaffolding influence behavior elicitation.",
    "Empirically evaluate these approaches (benchmarks/metrics and controlled experiments) to derive practical guidelines for eliciting behaviors across multiple turns."
  ],
  "impact": "Provides practitioners with a clearer taxonomy and tested practices for eliciting and evaluating model behaviors in realistic chat settings, improving robustness, evaluation fidelity, and safety of deployed conversational AI. It enables better prompt design, benchmark development, and risk assessment for multi-turn interactions.",
  "visual_elements": [
    "Flowchart of the analytical framework showing the three method families and how they relate to multi-turn phenomena",
    "Example conversation trace (dialogue timeline) highlighting where and how a prompt induces the target behavior across turns",
    "Bar/line chart comparing elicitation success rates for single-turn vs. multi-turn setups across representative methods",
    "Icon set summarizing practical guidelines (e.g., 'use scaffolding', 'monitor history', 'iterate prompts')"
  ],
  "hashtags": [
    "#PromptEngineering",
    "#ConversationalAI",
    "#LLMEvaluation",
    "#ModelBehavior",
    "#AIAlignment"
  ],
  "paper_id": "2025-12-29-arxiv-eliciting_behaviors_in_multi_turn_conversations",
  "paper_title": "Eliciting Behaviors in Multi-Turn Conversations",
  "paper_category": "Evaluation",
  "paper_date": "2025-12-29",
  "paper_authors": "Jing Huang, Shujian Zhang, Lun Wang, Andrew Hard, Rajiv Mathews",
  "paper_links": [
    {
      "title": "PDF",
      "url": "https://arxiv.org/pdf/2512.23701v1"
    }
  ],
  "generated_at": "2025-12-30T06:22:11.916764"
}