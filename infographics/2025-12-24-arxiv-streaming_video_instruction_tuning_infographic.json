{
  "key_insight": "Streamo is a real-time, instruction-tuned video LLM that generalizes across a wide range of streaming tasks (narration, action/event understanding, temporal grounding, and time-sensitive QA) by training on a large, diverse streaming instruction dataset.",
  "problem_solved": "Existing online video models are narrow (QA or captioning) or offline; this paper solves the challenge of building a low-latency, versatile streaming video assistant that understands and responds to continuous, time-sensitive visual input.",
  "method": [
    "Design a streaming-capable video+language model architecture that processes frames incrementally with temporal memory / causal attention to enable real-time responses.",
    "Instruction-tune the model on a large-scale, diverse dataset (Streamo-Instruct-465K) covering narration, event captioning, temporal grounding, action understanding, and time-sensitive QA.",
    "Produce task-conditioned outputs and interfaces so the same model can emit live narration, localize events in time, answer time-sensitive questions, and generate captions with low latency."
  ],
  "impact": "Enables practitioners to build interactive, low-latency video assistants for live applications (robotics, surveillance, accessibility, sports analytics) and advances multimodal LLM capabilities by combining streaming processing with large-scale instruction tuning.",
  "visual_elements": [
    "Pipeline diagram: live video frames → streaming encoder/temporal memory → LLM → multi-format outputs (narration, captions, temporal grounding).",
    "Timeline visualization showing event detection/temporal grounding and time-aligned answers/narration.",
    "Dataset infographic: Streamo-Instruct-465K — number of examples, task breakdown (narration, QA, grounding, captioning).",
    "Latency/comparison chart: Streamo vs prior online video models across latency, task coverage, and accuracy."
  ],
  "hashtags": [
    "#StreamingVideo",
    "#VideoLLM",
    "#InstructionTuning",
    "#RealTimeAI",
    "#Multimodal"
  ],
  "paper_id": "2025-12-24-arxiv-streaming_video_instruction_tuning",
  "paper_title": "Streaming Video Instruction Tuning",
  "paper_category": "Model",
  "paper_date": "2025-12-24",
  "paper_authors": "Jiaer Xia, Peixian Chen, Mengdan Zhang, Xing Sun, Kaiyang Zhou",
  "paper_links": [
    {
      "title": "PDF",
      "url": "https://arxiv.org/pdf/2512.21334v1"
    }
  ],
  "generated_at": "2025-12-25T06:23:31.319833"
}