{
  "key_insight": "Text-driven token pruning identifies and removes visual tokens irrelevant to the text prompt before temporal reasoning in SAM2, greatly reducing compute and memory while keeping segmentation quality high.",
  "problem_solved": "SAM2 pipelines propagate dense visual tokens across time, causing quadratic compute/memory growth and preventing scalable, real-time deployment for prompt-driven video object segmentation.",
  "method": [
    "Text-guided relevance scoring: compute per-token relevance to the input prompt to rank visual tokens.",
    "Token pruning and sparse propagation: drop low-relevance tokens and only forward salient tokens into temporal reasoning modules across frames.",
    "Dynamic control mechanism: adjustable pruning thresholds (or lightweight controllers) to trade off latency and segmentation fidelity."
  ],
  "impact": "Significantly lowers FLOPs and memory footprint of SAM2-based video segmentation, enabling faster, more deployable systems for real-time and edge AI applications.",
  "visual_elements": [
    "Pipeline diagram: image encoder → text-guided token scorer → token pruning → temporal module → segmentation output.",
    "Before/after frame overlays: token heatmaps showing pruned vs retained tokens on example frames.",
    "Bar chart: compute (FLOPs) and memory usage of baseline SAM2 vs pruned SAM2.",
    "Trade-off curve: segmentation accuracy vs fraction of tokens retained (showing steep gains with few tokens)."
  ],
  "hashtags": [
    "#TokenPruning",
    "#SAM2",
    "#EfficientVision",
    "#VideoSegmentation",
    "#EdgeAI"
  ],
  "paper_id": "2025-12-24-arxiv-fast_sam2_with_text_driven_token_pruning",
  "paper_title": "Fast SAM2 with Text-Driven Token Pruning",
  "paper_category": "Hardware/Infra",
  "paper_date": "2025-12-24",
  "paper_authors": "Avilasha Mandal, Chaoning Zhang, Fachrina Dewi Puspitasari, Xudong Wang, Jiaquan Zhang",
  "paper_links": [
    {
      "title": "PDF",
      "url": "https://arxiv.org/pdf/2512.21333v1"
    }
  ],
  "generated_at": "2025-12-27T06:21:49.092015"
}