{
  "key_insight": "Train autoregressive video diffusion models end-to-end without a separate teacher by using a self-resampling scheme that exposes the model to its own predicted frames during training, eliminating exposure bias from train-test mismatch.",
  "problem_solved": "Autoregressive video diffusion models suffer from exposure bias because they are trained on ground-truth conditioning but must condition on their own predictions at test time; prior fixes require an extra teacher model or online discriminator, increasing complexity and resource cost.",
  "method": [
    "Self-Resampling: during training, sample the model's own past-frame predictions and re-insert them into the conditioning context so the model learns to correct its own errors.",
    "Resampling Forcing Framework: a teacher-free, end-to-end training protocol that schedules and integrates resampled predictions into the loss to bridge the train-test distribution gap.",
    "Scalable Autoregressive Training: compatible with large-scale autoregressive video diffusion architectures, enabling training from scratch without bidirectional teachers or discriminators."
  ],
  "impact": "Simplifies and stabilizes training of autoregressive video diffusion models, improving robustness to compounding errors while reducing dependency on additional teacher models—useful for practitioners building scalable generative video systems.",
  "visual_elements": [
    "Schematic of autoregressive video generation pipeline showing ground-truth conditioning vs. self-resampled conditioning (before/after)",
    "Illustration of exposure bias: training on ground-truth frames but testing on model predictions, with arrows showing distribution shift",
    "Flowchart of Resampling Forcing: sample → inject predictions → compute loss → update model, annotated with scheduling/curriculum",
    "Performance chart comparing sample quality or error accumulation over time for baseline (teacher/discriminator) vs. self-resampling"
  ],
  "hashtags": [
    "#VideoDiffusion",
    "#AutoregressiveAI",
    "#ExposureBias",
    "#SelfResampling",
    "#EndToEndTraining"
  ],
  "paper_id": "2025-12-17-arxiv-end_to_end_training_for_autoregressive_video_diffusion_via_self_resampling",
  "paper_title": "End-to-End Training for Autoregressive Video Diffusion via Self-Resampling",
  "paper_category": "Model",
  "paper_date": "2025-12-17",
  "paper_authors": "Yuwei Guo, Ceyuan Yang, Hao He, Yang Zhao, Meng Wei",
  "paper_links": [
    {
      "title": "PDF",
      "url": "https://arxiv.org/pdf/2512.15702v1"
    }
  ],
  "generated_at": "2025-12-18T22:33:06.945497"
}